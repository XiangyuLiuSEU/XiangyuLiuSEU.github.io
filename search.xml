<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Git 使用笔记]]></title>
    <url>%2F2019%2F04%2F03%2Fgit-note%2F</url>
    <content type="text"><![CDATA[廖雪峰的 Git 教程 少用 Pull 多用 Fetch 和 Merge 见到很多人说过这个经验，原因就是 git pull 把过程的细节都隐藏了起来，大部分时候是没有问题的，但是当代码出错时可能会造成损失。很多时候我们宁愿做的慢一些，也不愿意返工重来 一般的做法是： 12git fetch origin # 下载远程分支的更新git merge origin/master # 合并远程分支到当前分支 如果你想在合并前查看本地分支和远程分支的差异，可以使用下面的命令： 1git diff master origin/master 单独进行下载和合并是一个好的做法，你可以先看看下载的是什么，然后再决定是否和本地代码合并，方便使用。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nvcc 编译报错：找不到 "cuda_runtime.h"]]></title>
    <url>%2F2019%2F04%2F02%2Fnvcc-fatal-error-cuda-runtime-h%2F</url>
    <content type="text"><![CDATA[奇怪的错误 今天在安装 PANet 时遇到了一个奇怪的错误： 12Compiling nms kernels by nvcc...cc1plus: fatal error: cuda_runtime.h: No such file or directory 按理说不应该出现这种奇怪的错误，cuda_runtime.h 就安静地躺在 /usr/local/cuda/include 目录下，cuda 安装是没有问题的，这个仓库在实验室的服务器上也跑过，完全没有问题。然而就是这样的错误费了老半天时间也无法定位原因，网上的解决办法无非就是环境变量的问题，多次确认之后环境变量是没有问题的 😩 难道要因为这个错误重装 cuda？ 重装是不太可能的，服务器上配环境太费事， 于是查看 nvcc 命令帮助，果然其中写着可以用 -I 选项指定包含头文件的路径，迅速在 PANet/lib/make.sh 中有关 nvcc 的命令加上 -I /usr/local/cuda/include ，运行，成功 😎 估计是环境变量出现了某种错误，虽然到最后也没有搞明白为什么会出现这个错误，但好歹是解决了这个问题。这个问题说明了遇事不能只靠百度，要自己好好分析]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过 SSH 隧道连接远程服务器的 Jupyter Notebook]]></title>
    <url>%2F2019%2F02%2F24%2FRemote-jupyter-notebook%2F</url>
    <content type="text"><![CDATA[参考: https://www.howtoing.com/how-to-install-run-connect-to-jupyter-notebook-on-remote-server 在远程服务器上没有安装浏览器的情况下，通过在本地建立 SSH 隧道的方法使用服务器的 Jupyter Notebook 1. 服务器端 首先确保服务器端安装了 Jupyter Notebook，如果需要使用 conda 环境，还要安装 ipykernel 等包 进入虚拟环境，运行 Jupyter Notebook 1jupyter notebook 根据输出的信息可以看到无法找到可用的浏览器 12345[I 09:56:37.551 NotebookApp] Serving notebooks from local directory: /home/liuxiangyu[I 09:56:37.551 NotebookApp] The Jupyter Notebook is running at:[I 09:56:37.552 NotebookApp] http://172.17.0.2:8888/?token=******[I 09:56:37.552 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[W 09:56:37.557 NotebookApp] No web browser found: could not locate runnable browser. 注意：如果报错信息提示地址已经被占用，那么久需要修改一下 Jupyter Notebook 的默认地址。修改方式如下： 配置 Jupyter Notebook 1jupyter notebook --generate-config 运行命令后将会在主目录下生成 .jupyter/jupyter_notebook_config.py 文件，打开文件找到 #c.NotebookApp.ip = 'localhost'，把 # 号去掉，localhost 改成自己的 ip 地址（在上面输出信息中可以看到） 保存后关闭文件，重启 Jupyter Notebook 即可 至此，服务器端的准备已经完成了，我们需要记住服务器的地址 172.17.0.2 和端口号 8008 2. 本地 以 Windows 系统为例，下载 putty 打开 putty 后在服务器地址和端口处正确填写信息，然后在左侧 ssh 选项下选择 Tunnels Source port 填写本地想用的端口号，以 8000 为例 Destination 填写 服务器地址 172.17.0.2:8888 其他选项不要修改，最后不要忘记点击 Add，然后连接即可 连接到服务器后进入相应的虚拟环境，运行 Jupyter Notebook，然后打开浏览器输入地址 https://localhost:8000 即可打开 notebook. 第一次进入 notebook 可能需要输入 token，按照提示输入相应的 token 即可 Done! 😎]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>env</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 安装步骤]]></title>
    <url>%2F2019%2F01%2F20%2Fdetectron-installation%2F</url>
    <content type="text"><![CDATA[Requirements： Linux 16.04, Python2, NVIDIA GPU (Detectron 目前只有 GPU 版本) CUDA 9.0, cuDNN7.0.5 Caffe2, COCO API 为保持 Python 环境的独立性与完整性，安装前新建一个新的虚拟环境，以下安装过程在虚拟环境中进行 123# 在主环境下conda create -n detectron python=2.7source activate detectron [TOC] CUDA &amp; cuDNN 安装 CUDA9.0 和 cuDNN7.0.5，具体安装步骤参考英伟达官网 Caffe2 1. 从源码编译 以下为源码编译的过程，尝试过安装 Pre-Built Binaries，结果失败了，也可以直接安装预编译文件（推荐），[2. 安装预编译文件](#2. 安装预编译文件) 安装依赖包 1234567891011121314151617181920212223242526sudo apt-get updatesudo apt-get install -y --no-install-recommends \ build-essential \ git \ libgoogle-glog-dev \ libgtest-dev \ libiomp-dev \ libleveldb-dev \ liblmdb-dev \ libopencv-dev \ libopenmpi-dev \ libsnappy-dev \ libprotobuf-dev \ openmpi-bin \ openmpi-doc \ protobuf-compiler \ python-dev \ python-pip \ libgflags-dev \ cmakepip install --user \ future \ numpy \ protobuf \ typing \ hypothesis pip install 使用默认镜像下载速度较慢，可以选择使用清华大学 pypi 镜像 123456# for temporary usepip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package# set to defaultpip install pip -U # upgrade pip to the latest version (&gt;=10.0.0)pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 下载代码仓库并编译 1234git clone https://github.com/pytorch/pytorch.git &amp;&amp; cd pytorchgit submodule update --init --recursive # 安装所需子模块conda install pyyaml # 安装缺少的依赖包python setup.py install 如果编译顺利通过，恭喜，接下来测试 caffe2 安装是否正确，[3. 安装后测试](#3. 安装后测试) 错误信息1：服务器安装的 git 在执行 clone 命令时报错找不到 https 协议，应该是安装不完整导致的，可以在当前环境下重新安装 git 后重试（使用命令 conda install git，推荐）或者使用以下命令代替： 1git clone git://github.com/pytorch/pytorch.git &amp;&amp; cd pytorch 错误信息2（未解决）：在执行安装命令时 (python setup.py install)，出现以下错误： 1······/libmklml_intel.so: file not recognized: File truncated. 该错误指向 pytorch/third_party/ideep/mkl-dnn/external/mklml_lnx_2019.0.1.20180928/lib/libmklml_intel.so 文件，可能是文件不完整导致的错误，但是未找到原因及解决方法。如果出现此错误请尝试通过预编译文件安装 caffe2. 其他错误：查看 Caffe2 troubleshooting 2. 安装预编译文件 Caffe2 只提供 Anaconda 的预编译安装包，需要安装 Anaconda 或 Miniconda 首先添加清华大学维护的 PyTorch 源，下载速度更快： 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 然后执行安装操作： 1conda install pytorch-nightly 3. 安装后测试 安装完成后，测试安装是否成功 123456# To check if Caffe2 build was successfulpython -c 'from caffe2.python import core' 2&gt;/dev/null &amp;&amp; echo "Success" || echo "Failure"# To check if Caffe2 GPU build was successful# This must print a number &gt; 0 in order to use Detectronpython -c 'from caffe2.python import workspace; print(workspace.NumCudaDevices())' 根据执行结果判断安装是否成功 从源码编译需注意： If the caffe2 Python package is not found, you likely need to adjust your PYTHONPATH environment variable to include its location (/path/to/caffe2/build, where build is the Caffe2 CMake build directory). COCO API 依赖： setuptools&gt;=18.0 cython&gt;=0.27.3 matplotlib&gt;=2.1.0 123456conda install setuptools cython matplotlibCOCOAPI=/path/to/clone/cocoapi # 指定安装路径git clone https://github.com/cocodataset/cocoapi.git $COCOAPIcd $COCOAPI/PythonAPImake#python setup.py install --user Detectron 下载代码仓库： 12DETECTRON=/path/to/clone/detectron # 指定安装路径git clone https://github.com/facebookresearch/detectron $DETECTRON 安装 Python 依赖： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r $DETECTRON/requirements.txt 然后 make: 1cd $DETECTRON &amp;&amp; make 安装完成后运行测试： 1python $DETECTRON/detectron/tests/test_spatial_narrow_as_op.py 结果输出 OK，安装完毕 输出以下提示信息不必理会： 12No handlers could be found for logger "caffe2.python.net_drawer"net_drawer will not run correctly. Please install the correct dependencies. Troubleshooting 参照 Detectron Troubleshooting Reference https://github.com/facebookresearch/Detectron/blob/master/INSTALL.md https://caffe2.ai/docs/getting-started.html?platform=ubuntu&amp;configuration=prebuilt https://blog.csdn.net/weixin_43624538/article/details/84712617 P.S. CUDA8.0 cuDNN5.1.10 安装失败，原因：PyTorch 需要 cuDNN&gt;=7.0 查看 CUDA 和 cuDNN 版本： 12345# CUDAcat /usr/local/cuda/version.txt# cuDNNcat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2]]></content>
      <categories>
        <category>安装</category>
      </categories>
      <tags>
        <tag>detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YOLOv3 安装步骤]]></title>
    <url>%2F2019%2F01%2F15%2FYOLOv3-installation%2F</url>
    <content type="text"><![CDATA[操作系统：Linux 16.04 依赖： CUDA OpenCV darknet 写在前面：conda 是一款非常好用的 python 环境管理工具，建议安装 Anaconda 或 Miniconda。安装及使用请参阅网上教程，安装完成后记得添加清华大学 tuna 镜像。 Anaconda 镜像使用帮助 CUDA 按照网上教程或英伟达官方网站正确安装 CUDA 和 cuDNN（实验室服务器上的版本是 cuda9.0 cudnn7.1） OpenCv 如果安装了 conda，首先进入你想要安装 YOLO 的虚拟环境。第一次使用 Anaconda 请先创建虚拟环境。 1conda create --name YOURNAME python=3.6 numpy pandas matplotlib （YOURNAME 替换为你想要的名字）上述命令将创建新的 python 虚拟环境，并安装常用工具包 numpy, pandas, matplotlib，创建完成后进入虚拟环境 12source activate YOURNAMEsource deactivate # use this one to exit 进入环境后开始安装 OpenCV 1conda install opencv 安装完毕即可 darknet 首先下载 github 仓库 12git clone https://github.com/AlexeyAB/darknet.gitcd darknet 然后打开 Makefile 文件，修改以下选项： 123GPU = 1CUDNN = 1OPENCV = 1 然后在 darknet 目录下执行 1make 如果没有报错，YOLOv3 就安装成功了。测试一下 1./darknet 可以看到输出为： 1usage: ./darknet &lt;function&gt; Reference https://github.com/AlexeyAB/darknet https://pjreddie.com/darknet/yolo/ 🦄]]></content>
      <categories>
        <category>安装</category>
      </categories>
      <tags>
        <tag>yolo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PANet 安装步骤]]></title>
    <url>%2F2019%2F01%2F15%2FPANet-installation%2F</url>
    <content type="text"><![CDATA[Requirements 操作系统：Linux 16.04 平台：PyTorch 依赖 pytorch = 0.4.0 torchvision &gt;= 0.2.0 cython matplotlib numpy scipy opencv pyyaml packaging pycocotools – for coco dataset tensorboardX – for logging in TensorBoard PyTorch 使用 conda 安装 PyTorch 比较简单，首先进入 conda 环境，然后执行 1conda install pytorch=0.4.0 torchvision cuda90 -c pytorch 其余 cython 等包都可以使用 conda install 或者 pip install 命令来安装，就不再重复了 编译 PANet 首先下载 github 仓库： 12git clone https://github.com/ShuLiu1993/PANet.gitcd PANet 然后编译 12cd lib # please change to this directorysh make.sh 等待编译完成即可。训练代码在 PANet/tools 文件夹下。 如果安装过程报错找不到 cuda_runtime.h，可以查看这里 Reference https://github.com/ShuLiu1993/PANet https://github.com/roytseng-tw/Detectron.pytorch]]></content>
      <categories>
        <category>安装</category>
      </categories>
      <tags>
        <tag>panet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查找回文字符串：马拉车算法 Manacher's Algorithm]]></title>
    <url>%2F2018%2F12%2F20%2FManacher-Algorithm%2F</url>
    <content type="text"><![CDATA[在 LeetCode 看到一个题，给定一个字符串，返回最大长度的回文子字符串。 Example: 12Input: "babad"Output: "bab" or "aba" 最简单的方法就是暴力循环遍历，但是算法复杂度为 $O(n^3)$, 因此记录一个线性复杂度的算法——马拉车算法。 LeetCode：https://leetcode.com/problems/longest-palindromic-substring 英文解释：https://articles.leetcode.com/longest-palindromic-substring-part-ii 中文解释：https://www.felix021.com/blog/read.php?2040 Manacher’s Algorithm 首先，假设输入字符串为 abaaba，显然输入即为最长的回文字符串，因此输出应为 abaaba。让我们分两步来解决这个问题。 1. 预处理 我们想一下可能会发现，回文字符串分为两种情况：奇数长度和偶数长度。这两种情况显然是无法直接合并处理的，因此马拉车算法首先对输入的字符串进行了一下处理：在每个字符的两侧插入一个特定字符 #，例如： 12S = &apos;abaaba&apos;T = &apos;#a#b#a#a#b#a#&apos; 这样做的好处是所有的字符串都变成了奇数长度，这样我们就不需要分别考虑了 预处理部分的代码如下： 123456def preProcess(self, s): l = [c for c in s] ret = '#'.join(l) # add ^ and $ at both bounds to avoid out of index problem return '^#'+ret+'#$' 2. 算法部分 算法的思想是这样的，对于一个预处理之后的字符串 T，定义一个具有相同长度的数组 P，使得 P[i] 等于以 T[i] 为中心的 T 中最长回文字符串的半径，对于上面的例子 12T = # a # b # a # a # b # a #P = 0 1 0 3 0 1 6 1 0 3 0 1 0 我们可以发现，P 具有某种对称性质，我们可以利用这个性质在一定程度上减小我们的计算复杂度。那么所有的情况都是对称的吗？可惜的是并不是，只有在某种特定的条件下这种情况才成立。但是没关系，我们一样可以利用这个性质减少计算，只是需要找到不满足这种情况的条件就可以了 我们来看一个稍微复杂一点的例子，S = ‘babcbabcbaccba’ 上图中假设当前 i 为 13， 实线表示回文字符串 abcbabcba的中心，虚线表示两侧的边界。我们可以看到，由于回文字符串的对称性质，我们可以快速的知道 P[13] 的值，也就是等于 P[9] 处的值。然后继续看 现在我们到了下标为 15 的位置，p[15] 的值是多少呢？如果我们继续根据对称性质，那么就会得到 P[15] = P[7] = 7，但很显然是错误的。 如果以 T[15] 为中心，我们得到的回文字符串为 #a#b#c#b#a#，而 T[7] 处的回文字符串要更长，这是因为我们当前的以 C 为中心的回文字符串并不能完全包含以 T[7] 为中心的回文字符串，因此就造成了不满足对称性质的情况。解决办法也很简单，只要取 P[i] = min(P[i'], R-i) 就可以了。 用伪代码总结一下： 123if P[i&apos;] &lt;= R - ithen P[i] = P[i&apos;]else P[i] &lt;= P[i&apos;] 然后我们需要确定 R 和 C 的更新策略：如果以 i 为中心的回文字符串的超过了 R，则令新的中心C = i，然后把 R 扩展到新的回文字符串的右边界。 全部代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution: def longestPalindrome(self, s): """ :type s: str :rtype: str """ # Manacher's algorithm T = self.preProcess(s) length = len(T) C, R = 0, 0 P = [0] * length i = 1 while i &lt; length-1: # i_mirror can reduce the computation of P[i] i_mirror = 2*C - i # equals to C - (i - C) P[i] = min(P[i_mirror], R-i) if R &gt; i else 0 # expand the palindrome centered at i while T[i + P[i] + 1] == T[i - P[i] - 1]: P[i] += 1 # adjust center if the expanded palindrome pasts R if R &lt; i + P[i]: C = i R = i + P[i] i += 1 maxLength = max(P) centerIndex = P.index(maxLength) start = (centerIndex - maxLength) // 2 stop = start + maxLength return s[start:stop] def preProcess(self, s): l = [c for c in s] ret = '#'.join(l) # add ^ and $ at both bounds to avoid out of index problem return '^#'+ret+'#$' 最后 按理说线性复杂度的算法已经是很快了，当然 LeetCode 上还有很多大神的神仙代码更快，反正我是看不懂…… 🙂 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch 调用 GPU 报 CUDA unknown error]]></title>
    <url>%2F2018%2F12%2F18%2Fpytorch-cuda-unknown-error%2F</url>
    <content type="text"><![CDATA[最近为了跑 PANet，在服务器上安装了 Detectron.pytorch，安装过程还挺顺利，但是只要调用 GPU 运算就报未知错误，网上搜索一番发现可能是显卡驱动安装有问题，导致 Torch 调用显卡时无法正常初始化。这里记录一下网上的解决方法。 报错信息 1RuntimeError: cuda runtime error (30) : unknown error at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/THCTensorRandom.cu:25 方法1：重新安装显卡驱动和 CUDA 既然是驱动问题，那么自然地重新安装一下最新版的显卡驱动应该就没问题了，注意驱动安装完成之后最好要重启一下机器。安装完驱动之后使用 conda 重新安装 PyTorch。但是由于服务器是公用资源，为了不影响同学使用，只得使用权宜之计。 方法2：root 权限运行 python 网上的解决方法除了重装驱动之外，还有一种暂时的解决办法。因为正确安装显卡驱动会保证 Torch 调用显卡时自动进行正常的初始化，那我也可以手动赋予 python root 权限去初始化显卡。 在尝试的过程中发现，由于服务器环境比较混乱，sudo 提升权限之后运行的不是我自己的 python，而且 PYTHONPATH 和 一些环境变量也不对。解决方法如下： 首先在 python 代码中加上 12345import osimport syssys.path.append('/path/to/cocoapi/PythonAPI') # my code needs pycocotoolsos.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID" # optionalos.environ["CUDA_VISIBLE_DEVICES"]="0" 然后在运行 1sudo /path/to/your/python tools/train_net_step.py --dataset dota --cfg xx.yml --use_tfboard 然后就可以开始训练了 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>cuda</tag>
        <tag>error</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译时遇到 /tmp 文件夹空间不足的解决办法]]></title>
    <url>%2F2018%2F12%2F11%2FNo-Space-in-tmp%2F</url>
    <content type="text"><![CDATA[今天在服务器上编译 PyTorch 时遇到了 /tmp 文件夹空间不足的问题，一般来说安装 Ubuntu 时给 / 挂载点分配足够的硬盘空间就不会遇到这个问题，但是服务器有很多人用，文件比较混乱，/挂载点已经达到了 100% 的空间使用率，因此百度到了一个解决办法 其实解决方法很简单，只需要在有硬盘空间的挂载点下（例如 /home ）新建一个临时文件夹供编译时临时使用就可以了 新建文件夹 在用户目录下新建临时文件夹，并使之生效即可 123cd /home/lxymkdir tmpexport TMPDIR = /home/lxy/tmp 这样重新执行编译命令就可以顺利编译了 还可以将最后一句代码写进 .bashrc 文件，然后 source 一下，以后临时文件都会存放在该临时文件夹 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将 DOTA 数据集的标注转换为 COCO 格式]]></title>
    <url>%2F2018%2F12%2F10%2FConvert-dataset-to-coco-like%2F</url>
    <content type="text"><![CDATA[DOTA 数据集：http://captain.whu.edu.cn/DOTAweb/index.html COCO 数据集：http://cocodataset.org/#download COCO API：https://github.com/cocodataset/cocoapi API make 报错，安装 Cython 即可 1conda install cython COCO 数据集简介 COCO 数据集包含 instance，keypoint 和 caption 等部分，本文只介绍 instance 相关内容 COCO 数据集的组织方式 coco ├── annos.txt (optional) ├── annotations ├── classes.txt (optional) └── images annotations 文件夹放数据集的标注文件（json格式），images 文件夹放数据集的所有图片，（annos.txt 放数据集的原始标注文件，class.txt 放标注的类别名称，每行一个类别，不含背景） COCO 的数据标注格式 COCO 数据集以 json 文件格式存储数据集的标注信息，标注的格式可以参考 官网 和这个 知乎专栏，在这里就不重复了。 确定了标注的格式以后，分析 DOTA 数据集的标注格式，可以提取其中的信息然后以 json 格式存储下来就可以了 格式转换脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import jsonimport dota_utils as utilimport osfrom PIL import Imageinfo = &#123;"description": "DOTA dataset from WHU", "url": "http://caption.whu.edu.cn", "year": 2018, "version": "1.0"&#125;licenses = &#123;"url": "http://creativecommons.org/licenses/by-nc/2.0/", "id": 1, "name": "Attribution-NonCommercial License"&#125;categories = []for i, catName in enumerate(util.wordname_15, start=1): categories.append(&#123;"id": i, "name": "%s" % catName, "supercategory": "%s" % catName&#125;)images = []annotations = []aug = "/home/lxy/dota/data/aug"augmented = "/home/lxy/dota/data/augmented"train_small = "/home/lxy/dota/data/train_small"trainsplit_HBB = "/home/lxy/dota/data/trainsplit_HBB"val_small = "/home/lxy/dota/data/val_small"valsplit_HBB = "/home/lxy/dota/data/valsplit_HBB"dataset_path = [augmented, train_small, trainsplit_HBB, val_small, valsplit_HBB]imgid = 0annid = 0for path in dataset_path: img_path = os.path.join(path, "images") label_path = os.path.join(path, "labelTxt") for file in os.listdir(label_path): img_name = file.replace("txt", "png") im = Image.open(os.path.join(img_path, img_name)) w, h = im.size imgid += 1 images.append(&#123;"license": 1, "file_name": "%s" % img_name, \ "height": h, "width": w, "id": imgid&#125;) f = open(os.path.join(label_path, file)) for line in f.readlines(): line = "".join(line).strip("\n").split(" ") # a bbox has 4 points, a category name and a difficulty if len(line) != 10: print(path, file) else: annid += 1 catid = util.wordname_15.index(line[-2]) + 1 w_bbox = int(line[4][:-2]) - int(line[0][:-2]) h_bbox = int(line[5][:-2]) - int(line[1][:-2]) bbox = [line[0], line[1], str(w_bbox)+'.0', str(h_bbox)+'.0'] annotations.append(&#123;"id": annid, "image_id": imgid, "category_id": catid, \ "segmentation": [line[0:8]], "area": float(w_bbox*h_bbox), \ "bbox": bbox, "iscrowd": 0&#125;) f.close()my_json = &#123;"info": info, "licenses": licenses, "images": images, "annotations": annotations, "categories": categories&#125;with open("/home/lxy/dota/data/coco/annotations/train.json", "w+") as f: json.dump(my_json, f) print("writing json file done!") 检查转换结果 这里需要用到 COCO API，具体用法参考 repo 里的 demo 文件，读取转换完成的数据集并显示标注结果，观察标注是否有误 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>数据集</tag>
        <tag>COCO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NP-Hard问题]]></title>
    <url>%2F2018%2F12%2F07%2FNP-Hard%2F</url>
    <content type="text"><![CDATA[简单理解 NP, P, NP-Complete 和 NP-Hard 参考：https://www.cnblogs.com/sancyun/p/4250360.html P 是一类可以通过确定性图灵机（以下简称 图灵机）在多项式时间 (Polynomial time) 内解决的问题集合。 NP 是一类可以通过非确定性图灵机 ( Non-deterministic Turing Machine) 在多项式时间 (Polynomial time) 内解决的决策问题集合。 P 是 NP 的子集，也就是说任何可以被图灵机在多项式时间内解决的问题都可以被非确定性的图灵机解决。 接下来说说 NP 里最难得问题 NP-Complete。 其定义如下， 如果一个决策问题 L 是 NP-Complete 的，那么 L 具备以下两个性质： L 是 NP（给定一个解决 NP-Complete 的方案 (solution，感兴趣的读者可以思考一下 solution 和 answer 的区别)，可以很快验证是否可行，但不存在已知高效的方案 。） NP 里的任何问题可以在多项式时间内转为 L。 而 NP-Hard 只需要具备 NP-Complete 的第二个性质，因此 NP-Complete 是 NP-Hard 的子集。 这四者的关系如下图（假设 P!= NP）：]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>NP-Hard</tag>
      </tags>
  </entry>
</search>
