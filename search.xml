<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python 装饰器的用法]]></title>
    <url>%2F2019%2F07%2F02%2Fpython-decorator%2F</url>
    <content type="text"><![CDATA[最近看了一些 Python 装饰器的用法，记录下来 01. 装饰器语法糖 如果你接触 Python 有一段时间了的话，想必你对 @ 符号一定不陌生了，没错 @ 符号就是装饰器的语法糖。 它放在一个函数开始定义的地方，它就像一顶帽子一样戴在这个函数的头上。和这个函数绑定在一起。在我们调用这个函数的时候，第一件事并不是执行这个函数，而是将这个函数做为参数传入它头顶上这顶帽子，这顶帽子我们称之为装饰函数 或 装饰器。 你要问我装饰器可以实现什么功能？我只能说你的脑洞有多大，装饰器就有多强大。 装饰器的使用方法很固定： 先定义一个装饰函数（帽子）（也可以用类、偏函数实现） 再定义你的业务函数、或者类（人） 最后把这顶帽子带在这个人头上 装饰器的简单的用法有很多，这里举两个常见的。 日志打印器 时间计时器 02. 入门用法：日志打印器 首先是日志打印器。 实现的功能： 在函数执行前，先打印一行日志告知一下主人，我要执行函数了。 在函数执行完，也不能拍拍屁股就走人了，咱可是有礼貌的代码，再打印一行日志告知下主人，我执行完啦。 12345678910# 这是装饰函数def logger(func): def wrapper(*args, **kw): print('我准备开始计算：&#123;&#125; 函数了:'.format(func.__name__)) # 真正执行的是这行。 func(*args, **kw) print('啊哈，我计算完啦。给自己加个鸡腿！！') return wrapper 假如，我的业务函数是，计算两个数之和。写好后，直接给它带上帽子。 123@loggerdef add(x, y): print('&#123;&#125; + &#123;&#125; = &#123;&#125;'.format(x, y, x+y)) 然后我们来计算一下。 1add(200, 50) 快来看看输出了什么，神奇不？ 123我准备开始计算：add 函数了:200 + 50 = 250啊哈，我计算完啦。给自己加个鸡腿！ 03. 入门用法：时间计时器 再来看看 时间计时器 实现功能： 顾名思义，就是计算一个函数的执行时长。 123456789101112# 这是装饰函数def timer(func): def wrapper(*args, **kw): t1=time.time() # 这是函数真正执行的地方 func(*args, **kw) t2=time.time() # 计算下时长 cost_time = t2-t1 print("花费时间：&#123;&#125;秒".format(cost_time)) return wrapper 假如，我们的函数是要睡眠10秒（冏~，小明实在不知道要举什么例子了）。这样也能更好的看出这个计算时长到底靠不靠谱。 1234567import time@timerdef want_sleep(sleep_time): time.sleep(sleep_time)want_sleep(10) 来看看，输出。真的是10秒耶。真历害！！！ 1花费时间：10.0073800086975098秒 04. 进阶用法：带参数的函数装饰器 通过上面简单的入门，你大概已经感受到了装饰的神奇魅力了。 不过，装饰器的用法远不止如此。我们今天就要把这个知识点讲透。 上面的例子，装饰器是不能接收参数的。其用法，只能适用于一些简单的场景。不传参的装饰器，只能对被装饰函数，执行固定逻辑。 如果你有经验，你一定经常在项目中，看到有的装饰器是带有参数的。 装饰器本身是一个函数，既然做为一个函数都不能携带函数，那这个函数的功能就很受限。只能执行固定的逻辑。这无疑是非常不合理的。而如果我们要用到两个内容大体一致，只是某些地方不同的逻辑。不传参的话，我们就要写两个装饰器。小明觉得这不能忍。 那么装饰器如何实现传参呢，会比较复杂，需要两层嵌套。 同样，我们也来举个例子。 我们要在这两个函数的执行的时候，分别根据其国籍，来说出一段打招呼的话。 12345def chinese(): print("我来自中国。")def american(): print("I am from America.") 在给他们俩戴上装饰器的时候，就要跟装饰器说，这个人是哪国人，然后装饰器就会做出判断，打出对应的招呼。 戴上帽子后，是这样的。 1234567@say_hello("china")def chinese(): print("我来自中国。")@say_hello("america")def american(): print("I am from America.") 万事俱备，只差帽子了。来定义一下，这里需要两层嵌套。 1234567891011121314def say_hello(contry): def wrapper(func): def deco(*args, **kwargs): if contry == "china": print("你好!") elif contry == "america": print('hello.') else: return # 真正执行函数的地方 func(*args, **kwargs) return deco return wrapper 执行一下 123american()print("------------")chinese() 看看输出结果。 12345你好!我来自中国。------------hello.I am from America emmmm，这很NB。。。 05. 高阶用法：不带参数的类装饰器 以上都是基于函数实现的装饰器，在阅读别人代码时，还可以时常发现还有基于类实现的装饰器。 基于类装饰器的实现，必须实现 __call__ 和 __init__两个内置函数。 __init__ ：接收被装饰函数 __call__ ：实现装饰逻辑。 1234567891011121314class logger(object): def __init__(self, func): self.func = func def __call__(self, *args, **kwargs): print("[INFO]: the function &#123;func&#125;() is running..."\ .format(func=self.func.__name__)) return self.func(*args, **kwargs)@loggerdef say(something): print("say &#123;&#125;!".format(something))say("hello") 执行一下，看看输出 12[INFO]: the function say() is running...say hello! 06. 高阶用法：带参数的类装饰器 上面不带参数的例子，你发现没有，只能打印INFO级别的日志，正常情况下，我们还需要打印DEBUG WARNING等级别的日志。 这就需要给类装饰器传入参数，给这个函数指定级别了。 带参数和不带参数的类装饰器有很大的不同。 __init__ ：不再接收被装饰函数，而是接收传入参数。 __call__ ：接收被装饰函数，实现装饰逻辑。 12345678910111213141516class logger(object): def __init__(self, level='INFO'): self.level = level def __call__(self, func): # 接受函数 def wrapper(*args, **kwargs): print("[&#123;level&#125;]: the function &#123;func&#125;() is running..."\ .format(level=self.level, func=func.__name__)) func(*args, **kwargs) return wrapper #返回函数@logger(level='WARNING')def say(something): print("say &#123;&#125;!".format(something))say("hello") 我们指定WARNING级别，运行一下，来看看输出。 12[WARNING]: the function say() is running...say hello! 07. wraps 装饰器有啥用？ 在 functools 标准库中有提供一个 wraps 装饰器，你应该也经常见过，那他有啥用呢？ 先来看一个例子 1234567891011def wrapper(func): def inner_function(): pass return inner_function@wrapperdef wrapped(): passprint(wrapped.__name__)#inner_function 为什么会这样子？不是应该返回 func 吗？ 这也不难理解，因为上边执行func 和下边 decorator(func) 是等价的，所以上面 func.__name__ 是等价于下面decorator(func).__name__ 的，那当然名字是 inner_function 12345678910def wrapper(func): def inner_function(): pass return inner_functiondef wrapped(): passprint(wrapper(wrapped).__name__)#inner_function 那如何避免这种情况的产生？方法是使用 functools .wraps 装饰器，它的作用就是将 被修饰的函数(wrapped) 的一些属性值赋值给 修饰器函数(wrapper) ，最终让属性的显示更符合我们的直觉。 1234567891011121314from functools import wrapsdef wrapper(func): @wraps(func) def inner_function(): pass return inner_function@wrapperdef wrapped(): passprint(wrapped.__name__)# wrapped 准确点说，wraps 其实是一个偏函数对象（partial），源码如下 12345def wraps(wrapped, assigned = WRAPPER_ASSIGNMENTS, updated = WRAPPER_UPDATES): return partial(update_wrapper, wrapped=wrapped, assigned=assigned, updated=updated) 可以看到wraps其实就是调用了一个函数update_wrapper，知道原理后，我们改写上面的代码，在不使用 wraps的情况下，也可以让 wrapped.__name__ 打印出 wrapped，代码如下： 1234567891011121314151617from functools import update_wrapperWRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__')def wrapper(func): def inner_function(): pass update_wrapper(inner_function, func, assigned=WRAPPER_ASSIGNMENTS) return inner_function@wrapperdef wrapped(): passprint(wrapped.__name__) 08. 使用偏函数与类实现装饰器 绝大多数装饰器都是基于函数和闭包实现的，但这并非制造装饰器的唯一方式。 事实上，Python 对某个对象是否能通过装饰器（ @decorator）形式使用只有一个要求：decorator 必须是一个“可被调用（callable）的对象。 对于这个 callable 对象，我们最熟悉的就是函数了。 除函数之外，类也可以是 callable 对象，只要实现了__call__ 函数（上面几个盒子已经接触过了），还有比较少人使用的偏函数也是 callable 对象。 接下来就来说说，如何使用 类和偏函数结合实现一个与众不同的装饰器。 如下所示，DelayFunc 是一个实现了 __call__ 的类，delay 返回一个偏函数，在这里 delay 就可以做为一个装饰器。（以下代码摘自 Python工匠：使用装饰器的小技巧） 12345678910111213141516171819202122232425import timeimport functoolsclass DelayFunc: def __init__(self, duration, func): self.duration = duration self.func = func def __call__(self, *args, **kwargs): print(f'Wait for &#123;self.duration&#125; seconds...') time.sleep(self.duration) return self.func(*args, **kwargs) def eager_call(self, *args, **kwargs): print('Call without delay') return self.func(*args, **kwargs)def delay(duration): """ 装饰器：推迟某个函数的执行。 同时提供 .eager_call 方法立即执行 """ # 此处为了避免定义额外函数， # 直接使用 functools.partial 帮助构造 # DelayFunc 实例 return functools.partial(DelayFunc, duration) 我们的业务函数很简单，就是相加 123@delay(duration=2)def add(a, b): return a+b 来看一下执行过程 123456789&gt;&gt;&gt; add # 可见 add 变成了 Delay 的实例&lt;__main__.DelayFunc object at 0x107bd0be0&gt;&gt;&gt;&gt; &gt;&gt;&gt; add(3,5) # 直接调用实例，进入 __call__Wait for 2 seconds...8&gt;&gt;&gt; &gt;&gt;&gt; add.func # 实现实例方法&lt;function add at 0x107bef1e0&gt; 09. 内置装饰器：property 以上，我们介绍的都是自定义的装饰器。 其实Python语言本身也有一些装饰器。比如property这个内建装饰器，我们再熟悉不过了。 它通常存在于类中，可以将一个函数定义成一个属性，属性的值就是该函数return的内容。 通常我们给实例绑定属性是这样的 12345678910111213141516class Student(object): def __init__(self, name, age=None): self.name = name self.age = age# 实例化XiaoMing = Student("小明")# 添加属性XiaoMing.age=25# 查询属性XiaoMing.age# 删除属性del XiaoMing.age 但是稍有经验的开发人员，一下就可以看出，这样直接把属性暴露出去，虽然写起来很简单，但是并不能对属性的值做合法性限制。为了实现这个功能，我们可以这样写。 1234567891011121314151617181920212223242526272829class Student(object): def __init__(self, name): self.name = name self.name = None def set_age(self, age): if not isinstance(age, int): raise ValueError('输入不合法：年龄必须为数值!') if not 0 &lt; age &lt; 100: raise ValueError('输入不合法：年龄范围必须0-100') self._age=age def get_age(self): return self._age def del_age(self): self._age = NoneXiaoMing = Student("小明")# 添加属性XiaoMing.set_age(25)# 查询属性XiaoMing.get_age()# 删除属性XiaoMing.del_age() 上面的代码设计虽然可以变量的定义，但是可以发现不管是获取还是赋值（通过函数）都和我们平时见到的不一样。 按照我们思维习惯应该是这样的。 12345# 赋值XiaoMing.age = 25# 获取XiaoMing.age 那么这样的方式我们如何实现呢。请看下面的代码。 12345678910111213141516171819202122232425262728293031class Student(object): def __init__(self, name): self.name = name self.name = None @property def age(self): return self._age @age.setter def age(self, value): if not isinstance(value, int): raise ValueError('输入不合法：年龄必须为数值!') if not 0 &lt; value &lt; 100: raise ValueError('输入不合法：年龄范围必须0-100') self._age=value @age.deleter def age(self): del self._ageXiaoMing = Student("小明")# 设置属性XiaoMing.age = 25# 查询属性XiaoMing.age# 删除属性del XiaoMing.age 用@property装饰过的函数，会将一个函数定义成一个属性，属性的值就是该函数return的内容。同时，会将这个函数变成另外一个装饰器。就像后面我们使用的@age.setter和@age.deleter。 @age.setter 使得我们可以使用XiaoMing.age = 25这样的方式直接赋值。 @age.deleter 使得我们可以使用del XiaoMing.age这样的方式来删除属性。 10. 其他装饰器：装饰器实战 读完并理解了上面的内容，你可以说是Python高手了。别怀疑，因为很多人都不知道装饰器有这么多用法呢。 在小明看来，使用装饰器，可以达到如下目的： 使代码可读性更高，逼格更高； 代码结构更加清晰，代码冗余度更低； 刚好我最近在写代码的时候也有一个场景，可以用装饰器很好的实现，暂且放上来看看。 这是一个实现控制函数运行超时的装饰器。如果超时，则会抛出超时异常。 有兴趣的可以看看。 12345678910111213141516171819import signalclass TimeoutException(Exception): def __init__(self, error='Timeout waiting for response from Cloud'): Exception.__init__(self, error)def timeout_limit(timeout_time): def wraps(func): def handler(signum, frame): raise TimeoutException() def deco(*args, **kwargs): signal.signal(signal.SIGALRM, handler) signal.alarm(timeout_time) func(*args, **kwargs) signal.alarm(0) return deco return wraps 以上就是个人对装饰器用法的理解，整理不易，若对你有所帮助，不防给个赞呗。 上文来自：https://zhuanlan.zhihu.com/p/65968462]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拒绝遗忘：高效的动态规划算法]]></title>
    <url>%2F2019%2F06%2F05%2Fdynamic-programming%2F</url>
    <content type="text"><![CDATA[乔治·桑塔亚纳说过，“那些遗忘过去的人注定要重蹈覆辙。”这句话放在问题求解过程中也同样适用。不懂动态规划的人会在解决过的问题上再次浪费时间，懂的人则会事半功倍。那么什么是动态规划？这种算法有何神奇之处？本文作者给出了初步的解答。 假设你正在使用适当的输入数据进行一些计算。你在每个实例中都进行了一些计算，以便得到一些结果。当你提供相同的输入时，你不知道会有相同的输出。这就像你在重新计算之前已经计算好的特定结果一样。 那么问题出在哪里呢？你之前计算某些结果的宝贵时间被浪费掉了。你可以通过保存之前的计算结果去轻易地解决这个问题。比如通过使用恰当的数据结构。举个例子，你可以将输入输出作为键值对映射保存起来。 那些遗忘过去的人注定要重蹈覆辙 ~ 动态规划 现在通过分析这个问题，我们可以将新的输入（或者不在数据结构中的输入）与其对应的输出存储下来。或者在字典中查找输入并返回相应的输出结果。这样当你在进行一些计算时，你可以检查数据结构中是否存在该输入，如果数据输入存在的话就可以直接获得结果。我们将与这种方法相关的技巧称作动态规划。 详解动态规划 现在让我们更详细地介绍动态规划。 简而言之，我们可以说动态规划主要用来解决一些希望找到问题最优解的优化问题。 一种可以用动态规划解决的情况就是会有反复出现的子问题，然后这些子问题还会包含更小的子问题。相比于不断尝试去解决这些反复出现的子问题，动态规划会尝试一次解决更小的子问题。之后我们可以将结果输出记录在表格中，我们在之后的计算中可以把这些记录作为问题的原始解。 举个例子，斐波那契数列 $0,1,1,2,3,5,8,13,…$ 有着一个相当简单的描述方式，它的每个数字都与前两个紧邻的数字相关。如果 $F(n)$ 是第 $n$ 个数字，那么我们会有 $F(n) = F(n-1) + F(n-2)$。这个在数学上称作递归方程 或者递推关系。为了计算后面的项，它需要前面项的计算结果作为输入。 大多数动态规划问题都能被归类成两种类型： 优化问题 组合问题 优化问题希望你选择一个可行的解决方案，以便最小化或最大化所需函数的值。组合问题希望你弄清楚做某事方案的数量或某些事件发生的概率。 解决方案的对比：自上而下或者自下而上 以下是两种不同的动态规划解决方案： 自上而下：你从最顶端开始不断地分解问题，直到你看到问题已经分解到最小并已得到解决，之后只用返回保存的答案即可。这叫做记忆存储（Memoization）。 自下而上：你可以直接开始解决较小的子问题，从而获得最好的解决方案。在此过程中，你需要保证在解决问题之前先解决子问题。这可以称为表格填充算法（Tabulation，table-filling algorithm）。 至于迭代和递归与这两种方法的关系，自下而上用到了迭代技术，而自上而下则用到了递归技术。 图片中的展示在理论上可能并不完全正确，但这是一种可以理解的展示方式。 这儿有一个普通方法和动态规划方法的比较，你可以看到两者时间复杂度的不同。 Memoization 的准则：不要忘记 Jeff Erickson 在他的笔记中这样描述斐波那契数列： 递归算法之所以速度慢，是因为它一遍又一遍地计算了相同的斐波那契数列。 来自 Jeff Erickson 笔记：http://jeffe.cs.illinois.edu/ 我们可以通过记录递归调用的结果来加速递归算法，这样在之后需要这些结果时就不必重新计算了。 Memoization 是指缓存和重用之前计算结果的技术。 如果你使用 Memoization 来解决问题，可以通过维护已经解决的子问题的映射来实现（正如我们之前讨论的键值对映射）。你首先解决「上层」问题（通常是为了解决子问题而进行递归），这样做是「自上而下」。 memoization的伪代码 因此在使用递归的过程中，我们使用额外的内存（即这里的 lookup）来执行操作以存储结果。如果查找命中存储值，我们将直接返回它，或者将其添加到特定索引。 请记住，额外的内存与表格填充之间存在一个权衡。 自上而下的方法 Tabulation：以表格形式填充 但是一旦我们看到数组（存储的解决方案）是如何被填充的，我们就可以用一个简单的循环替换递归，这个循环有意地按顺序填充数组，而不是依赖于复杂的递归来为我们完成。 来自 Jeff Erickson 的笔记：http://jeffe.cs.illinois.edu/ Tabulation 以「自下而上」的方式进行。它更直接，会计算所有值，但需要的开销更少，因为它不必维护映射并以表格形式为每个值存储数据。它还可以计算不必要的值。如果你只想计算问题的所有值，则可以使用此方法。 tabulation的伪代码： 斐波那契树的伪代码 正如您可以在图片中看到的伪代码（右侧），它会进行迭代（即循环直到数组结束）。它从 fib(0),fib(1),fib(2),…开始，所以使用 tabulation 方法，我们可以消除递归，只需通过循环元素返回结果。 追根溯源 Richard bellman 是这个概念的提出者。他在 20 世纪 50 年代中期为兰德公司工作时想到了这一点。选择「dynamic programming」这个名字的原因是为了隐藏他为这项研究所做的数学工作。因为他担心他的老板会反对或不喜欢任何类型的数学研究。 所以「programming」这个词只是一个参考，以表明这是一种老式的计划或调度方式，通常是通过逐渐填充表格（以动态方式而不是线性方式）而不是一次全部填入的方式进行。 原文链接：https://medium.freecodecamp.org/an-intro-to-algorithms-dynamic-programming-dd00873362bb 本文链接：https://www.jiqizhixin.com/articles/2019-06-04-6]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[感知机不能表示异或 (XOR)]]></title>
    <url>%2F2019%2F06%2F03%2Fperceptron-xor%2F</url>
    <content type="text"><![CDATA[首先，我们分析一下什么是感知机， 所谓感知机就是：假设输入空间(即特征空间)是，输出空间是，输入表示实例的特征向量，对于输入空间的点，输出表示实例的类别。由输入空间到输出空间的映射如下所示： $$ f(x)=\text{sign}(w \cdot x+b) ​$$ 其中 $\text{sign}$ 是符号函数，$w$ 和 $b$ 是感知机参数。 通过定义可以发现感知机是一种线性分类模型。那么异或问题是什么呢？异或可以表示为如下形式： 即异或问题可以分为根据输出可以分为两类，显示在二维坐标系中如上图（右）所示：其中输出结果为1对应右图中红色的十字架，输出为0对应右图中蓝色的圆圈，我们可以发现对于这种情况无法找到一条直线将两类结果分开。即感知机无法找到一个线性模型对异或问题进行划分。 其实不光感知机无法处理异或问题，所有的线性分类模型都无法处理异或分类问题。 原文：https://blog.csdn.net/yangfeisc/article/details/45486067 感知机有关的博客： https://www.zybuluo.com/ArrowLLL/note/827264 https://zhuanlan.zhihu.com/p/30155870]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>统计学习方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几种范数 (norm) 的简单介绍]]></title>
    <url>%2F2019%2F06%2F02%2Fnorm-intro%2F</url>
    <content type="text"><![CDATA[什么是范数？ 我们知道距离的定义是一个宽泛的概念，只要满足非负、自反、三角不等式就可以称之为距离。范数是一种强化了的距离概念，它在定义上比距离多了一条数乘的运算法则。有时候为了便于理解，我们可以把范数当作距离来理解。 在数学上，范数包括向量范数和矩阵范数，向量范数表征向量空间中向量的大小，矩阵范数表征矩阵引起变化的大小。一种非严密的解释就是，对应向量范数，向量空间中的向量都是有大小的，这个大小如何度量，就是用范数来度量的，不同的范数都可以来度量这个大小，就好比米和尺都可以来度量远近一样；对于矩阵范数，学过线性代数，我们知道，通过运算 $AX=B​$，可以将向量 $X​$ 变化为 $B​$，矩阵范数就是来度量这个变化大小的。 这里简单地介绍以下几种向量范数的定义和含义 1、 L-P范数 与闵可夫斯基距离的定义一样，L-P 范数不是一个范数，而是一组范数，其定义如下： $$ L_{p} = ||\text{x}||_{p} = \sqrt[p]{\sum_{i=1}{n}{x_ip}},\ \text{x}=(x_1, x_2, …, x_n) $$ 根据 P 的变化，范数也有着不同的变化，一个经典的有关 P 范数的变化图如下： 上图表示了 p 从无穷到 0 变化时，三维空间中到原点的距离（范数）为 1 的点构成的图形的变化情况。以常见的 L-2 范数（p=2）为例，此时的范数也即欧氏距离，空间中到原点的欧氏距离为 1 的点构成了一个球面。 实际上，在 0 时，Lp 并不满足三角不等式的性质，也就不是严格意义下的范数。以 p=0.5，二维坐标 (1,4)、(4,1)、(1,9)为例，$ \sqrt[0.5]{1+\sqrt{4}}+\sqrt[0.5]{1+\sqrt{4}}&lt;\sqrt[0.5]{1+\sqrt{9}} $。因此这里的 L-P 范数只是一个概念上的宽泛说法。 2、L0范数 当 P=0 时，也就是 L0 范数，由上面可知，L0 范数并不是一个真正的范数，它主要被用来度量向量中非零元素的个数。用上面的 L-P 定义可以得到的 L-0 的定义为： $$ ||\text{x}||0=\sqrt[0]{\sum{i=0}n{x_i0}} $$ 这里就有点问题了，我们知道非零元素的零次方为 1，但零的零次方，非零数开零次方都是什么鬼，很不好说明 L0 的意义，所以在通常情况下，大家都用的是： $$ ||\text{x}||_0=#(i|x_i\neq0) $$ 表示向量 x 中非零元素的个数。 对于 L0 范数，其优化问题为： $$ \text{min}||\text{x}||_0, \ \text{s.t. }A\text{x}=b $$ 在实际应用中，由于 L0 范数本身不容易有一个好的数学表示形式，给出上面问题的形式化表示是一个很难的问题，故被人认为是一个 NP 难问题。所以在实际情况中，L0 的最优问题会被放宽到 L1 或 L2 下的最优化。 3、L1范数 L1 范数是我们经常见到的一种范数，它的定义如下： $$ ||\text{x}||1=\sum{i=1}^n{|x_i|} ​$$ 表示向量 $\text{x}$ 中非零元素的绝对值之和。 L1 范数有很多的名字，例如我们熟悉的曼哈顿距离、最小绝对误差等。使用 L1 范数可以度量两个向量间的差异，如绝对误差和（Sum of Absolute Difference）： $$ \text{SAD}(x_1, x_2)=\sum_i^n{|x_{1i}-x_{2i}|} ​$$ 对于 L1 范数，它的优化问题如下： $$ \text{min}||\text{x}||_1, \ \text{s.t. }A\text{x}=b ​$$ 由于 L1 范数的天然性质，对 L1 优化的解是一个稀疏解，因此 L1 范数也被叫做稀疏规则算子。通过 L1 可以实现特征的稀疏，去掉一些没有信息的特征，例如在对用户的电影爱好做分类的时候，用户有 100 个特征，可能只有十几个特征是对分类有用的，大部分特征如身高体重等可能都是无用的，利用 L1 范数就可以过滤掉。 4、L2范数 L2 范数是我们最常见最常用的范数了，我们用的最多的度量距离欧氏距离就是一种 L2 范数，它的定义如下： $$ ||\text{x}||2=\sum{i=1}n{x_i2} $$ 表示向量元素的平方和再开平方。 像 L1 范数一样，L2 也可以度量两个向量间的差异，如平方差和（Sum of Squared Difference）: $$ \text{SSD}(x_1, x_2)=\sum_in{(x_{1i}-x_{2i})2} $$ 对于L2范数，它的优化问题如下： $$ \text{min}||\text{x}||_2, \ \text{s.t. }A\text{x}=b $$ L2 范数通常会被用来做优化目标函数的正则化项，防止模型为了迎合训练集而过于复杂造成过拟合的情况，从而提高模型的泛化能力。 5、$L_{\infty}$范数 当 $P=\infty$ 时，也就是 $L_{\infty}$ 范数，它主要被用来度量向量元素的最大值，与 L0 一样，通常情况下表示为 $$ ||\text{x}||_{\infty}=\text{max}(|x_i|)$$ 来表示 $L_{\infty}​$ 作者：SethChai 来源：CSDN 原文：https://blog.csdn.net/a493823882/article/details/80569888 版权声明：本文为博主原创文章，转载请附上博文链接！]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>统计学习方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.寻找两个有序数组的中位数]]></title>
    <url>%2F2019%2F06%2F01%2Ffind-median-of-two-sorted-lists%2F</url>
    <content type="text"><![CDATA[方法：递归法 为了解决这个问题，我们需要理解 “中位数的作用是什么”。在统计中，中位数被用来： 将一个集合划分为两个长度相等的子集，其中一个子集中的元素总是大于另一个子集中的元素。 如果理解了中位数的划分作用，我们就很接近答案了。 首先，让我们在任一位置 ii 将 \text{A}A 划分成两个部分： 12 left_A | right_AA[0], A[1], ..., A[i-1] | A[i], A[i+1], ..., A[m-1] 由于 \text{A}A 中有 mm 个元素， 所以我们有 m+1m+1 种划分的方法（i = 0 \sim mi=0∼m）。 我们知道： $$\text{len}(\text{left_A}) = i, \text{len}(\text{right_A}) = m - i.$$ 注意：当 $i = 0$ 时，$\text{left_A}$ 为空集， 而当 $i = m$ 时, $\text{right_A}$ 为空集。 采用同样的方式，我们在任一位置 $ j$ 将 $\text{B}$ 划分成两个部分： 12 left_B | right_BB[0], B[1], ..., B[j-1] | B[j], B[j+1], ..., B[n-1] 将 $\text{left_A}$ 和 $\text{left_B}$ 放入一个集合，并将 $\text{right_A}$ 和 $\text{right_B}$ 放入另一个集合。 再把这两个新的集合分别命名为 $\text{left_part}$ 和 $\text{right_part}$： 123 left_part | right_partA[0], A[1], ..., A[i-1] | A[i], A[i+1], ..., A[m-1]B[0], B[1], ..., B[j-1] | B[j], B[j+1], ..., B[n-1] 如果我们可以确认： $\text{len}(\text{left_part}) = \text{len}(\text{right_part})​$ $\max(\text{left_part}) \leq \min(\text{right_part})​$ 那么，我们已经将 ${\text{A}, \text{B}}$ 中的所有元素划分为相同长度的两个部分，且其中一部分中的元素总是大于另一部分中的元素。那么： $$\text{median} = \frac{\text{max}(\text{left}_\text{part}) + \text{min}(\text{right}_\text{part})}{2}$$ 要确保这两个条件，我们只需要保证： $i + j = m - i + n - j$（或：$m - i + n - j + 1$） 如果 $n \geq m$，只需要使 $ i = 0 \sim m,\ j = \frac{m + n + 1}{2} - i $ $\text{B}[j-1] \leq \text{A}[i]$ 以及 $\text{A}[i-1] \leq \text{B}[j]$ ps.1 为了简化分析，我假设 $\text{A}[i-1], \text{B}[j-1], \text{A}[i], \text{B}[j]$ 总是存在，哪怕出现 $i=0，i=m，j=0$ 或是 $j=n$ 这样的临界条件。 我将在最后讨论如何处理这些临界值。 ps.2 为什么 $n \geq m$？由于$0 \leq i \leq m$ 且 $j = \frac{m + n + 1}{2} - i$，我必须确保 $j$ 不是负数。如果 $n &lt; m$，那么 $j$ 将可能是负数，而这会造成错误的答案。 所以，我们需要做的是： 在 $[0，m]​$ 中搜索并找到目标对象 $i​$，以使： $\qquad \text{B}[j-1] \leq \text{A}[i]$ 且 $\text{A}[i-1] \leq \text{B}[j]$ 其中 $j = \frac{m + n + 1}{2} - i$ 接着，我们可以按照以下步骤来进行二叉树搜索： 设 $\text{imin} = 0$，$\text{imax} = m$, 然后开始在 $[\text{imin}, \text{imax}]$ 中进行搜索。 令 $i = \frac{\text{imin} + \text{imax}}{2}$， $j = \frac{m + n + 1}{2} - i$ 现在我们有 $\text{len}(\text{left}_\text{part})=\text{len}(\text{right}_\text{part})$。 而且我们只会遇到三种情况： $\text{B}[j-1] \leq \text{A}[i]$ 且 $\text{A}[i-1] \leq \text{B}[j]$： 这意味着我们找到了目标对象 $i$，所以可以停止搜索。 $\text{B}[j-1] &gt; \text{A}[i]$： 这意味着 $\text{A}[i]$ 太小，我们必须调整 $i$ 以使 $\text{B}[j-1] \leq \text{A}[i]$。 我们可以增大 $i$ 吗？ 是的，因为当 $i$ 被增大的时候，$j$ 就会被减小。 因此 $\text{B}[j-1]$ 会减小，而 $\text{A}[i]$ 会增大，那么 $\text{B}[j-1] \leq \text{A}[i]$ 就可能被满足。 我们可以减小 $i$ 吗？ 不行，因为当 $i$ 被减小的时候，$j$ 就会被增大。 因此 $\text{B}[j-1]$ 会增大，而 $\text{A}[i]$ 会减小，那么 $\text{B}[j-1] \leq \text{A}[i]$ 就可能不满足。 所以我们必须增大 $i$。也就是说，我们必须将搜索范围调整为 $[i+1, \text{imax}]$。 因此，设 $\text{imin} = i+1​$，并转到步骤 2。 $\text{A}[i-1] &gt; \text{B}[j]$： 这意味着 $\text{A}[i-1]$ 太大，我们必须减小 $i$ 以使 $\text{A}[i-1]\leq \text{B}[j]$。 也就是说，我们必须将搜索范围调整为 $[\text{imin}, i-1]$。 因此，设 $\text{imax} = i-1$，并转到步骤 2。 当找到目标对象 $i$ 时，中位数为： $\max(\text{A}[i-1], \text{B}[j-1])$, 当 $m + n$ 为奇数时 $\frac{\max(\text{A}[i-1], \text{B}[j-1]) + \min(\text{A}[i], \text{B}[j])}{2}$, 当 $m + n​$ 为偶数时 现在，让我们来考虑这些临界值 $i=0,i=m,j=0,j=n$，此时 $\text{A}[i-1],\text{B}[j-1],\text{A}[i],\text{B}[j]​$ 可能不存在。 其实这种情况比你想象的要容易得多。 我们需要做的是确保 $\text{max}(\text{left}_\text{part}) \leq \text{min}(\text{right}_\text{part})$。 因此，如果 $i$ 和 $j$ 不是临界值（这意味着 $\text{A}[i-1], \text{B}[j-1],\text{A}[i],\text{B}[j]$ 全部存在）, 那么我们必须同时检查 $\text{B}[j-1] \leq \text{A}[i]$ 以及 $\text{A}[i-1] \leq \text{B}[j]$ 是否成立。 但是如果 $\text{A}[i-1],\text{B}[j-1],\text{A}[i],\text{B}[j]$ 中部分不存在，那么我们只需要检查这两个条件中的一个（或不需要检查）。 举个例子，如果 $i = 0$，那么 $\text{A}[i-1]$ 不存在，我们就不需要检查 $\text{A}[i-1] \leq \text{B}[j]$ 是否成立。 所以，我们需要做的是： 在 $[0，m]$ 中搜索并找到目标对象 $i​$，以使： ($j = 0$ or $i = m$ or $\text{B}[j-1] \leq \text{A}[i]$) 或是 ($i = 0$ or $j = n$ or $\text{A}[i-1] \leq \text{B}[j]$), 其中 $j = \frac{m + n + 1}{2} - i$ 在循环搜索中，我们只会遇到三种情况： ($j = 0$ or $i = m$ or $\text{B}[j-1] \leq \text{A}[i]$) 或是 ($i = 0$ or $j = n$ or $\text{A}[i-1] \leq \text{B}[j]$)，这意味着 $i​$ 是完美的，我们可以停止搜索。 $j &gt; 0$ and $i &lt; m$ and $\text{B}[j - 1] &gt; \text{A}[i]$ 这意味着 $i$ 太小，我们必须增大它。 $i &gt; 0$ and $j &lt; n$ and $\text{A}[i - 1] &gt; \text{B}[j]$ 这意味着 $i$ 太大，我们必须减小它。 感谢 @Quentin.chen 指出：$i &lt; m \implies j &gt; 0$ 以及 $i &gt; 0 \implies j &lt; n$ 始终成立，这是因为： $$m \leq n,\ i &lt; m \implies j = \frac{m+n+1}{2} - i &gt; \frac{m+n+1}{2} - m \geq \frac{2m+1}{2} - m \geq 0$$ $$m \leq n,\ i &gt; 0 \implies j = \frac{m+n+1}{2} - i &lt; \frac{m+n+1}{2} \leq \frac{2n+1}{2} \leq n​$$ 所以，在情况 2 和 3中，我们不需要检查 $j &gt; 0$ 或是 $j &lt; n$ 是否成立。 12345678910111213141516171819202122232425262728293031def median(A, B): m, n = len(A), len(B) if m &gt; n: A, B, m, n = B, A, n, m if n == 0: raise ValueError imin, imax, half_len = 0, m, (m + n + 1) / 2 while imin &lt;= imax: i = (imin + imax) / 2 j = half_len - i if i &lt; m and B[j-1] &gt; A[i]: # i is too small, must increase it imin = i + 1 elif i &gt; 0 and A[i-1] &gt; B[j]: # i is too big, must decrease it imax = i - 1 else: # i is perfect if i == 0: max_of_left = B[j-1] elif j == 0: max_of_left = A[i-1] else: max_of_left = max(A[i-1], B[j-1]) if (m + n) % 2 == 1: return max_of_left if i == m: min_of_right = B[j] elif j == n: min_of_right = A[i] else: min_of_right = min(A[i], B[j]) return (max_of_left + min_of_right) / 2.0 复杂度分析 时间复杂度：$O\big(\log\big(\text{min}(m,n)\big)\big)$， 首先，查找的区间是 $[0, m]$。 而该区间的长度在每次循环之后都会减少为原来的一半。 所以，我们只需要执行 $\log(m)$ 次循环。由于我们在每次循环中进行常量次数的操作，所以时间复杂度为 $O\big(\log(m)\big)$。 由于 $m \leq n$，所以时间复杂度是 $O\big(\log\big(\text{min}(m,n)\big)\big)​$。 空间复杂度：$O(1)$， 我们只需要恒定的内存来存储 9 个局部变量， 所以空间复杂度为 $O(1)$。]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是动态规划]]></title>
    <url>%2F2019%2F04%2F04%2Fwhat-is-dynamic-programming%2F</url>
    <content type="text"><![CDATA[0. intro 很有意思的问题。以往见过许多教材，对动态规划（DP）的引入属于“奉天承运，皇帝诏曰”式：不给出一点引入，见面即拿出一大堆公式吓人；学生则死啃书本，然后突然顿悟。针对入门者的教材不应该是这样的。恰好我给入门者讲过四次DP入门，迭代出了一套比较靠谱的教学方法，所以今天跑过来献丑。 现在，我们试着自己来一步步“重新发明”DP。 1. 从一个生活问题谈起 先来看看生活中经常遇到的事吧——假设您是个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在您的目标是凑出某个金额w，需要用到尽量少的钞票。 依据生活经验，我们显然可以采取这样的策略：能用100的就尽量用100的，否则尽量用50的……依次类推。在这种策略下，666=6×100+1×50+1×10+1×5+1×1，共使用了10张钞票。 这种策略称为“贪心”：假设我们面对的局面是“需要凑出w”，贪心策略会尽快让w变得更小。能让w少100就尽量让它少100，这样我们接下来面对的局面就是凑出w-100。长期的生活经验表明，贪心策略是正确的。 但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果一个奇葩国家的钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错： 15=1×11+4×1 （贪心策略使用了5张钞票） 15=3×5 （正确的策略，只用3张钞票） 为什么会这样呢？贪心策略错在了哪里？ 鼠目寸光。 刚刚已经说过，贪心策略的纲领是：“尽量使接下来面对的w更小”。这样，贪心策略在w=15的局面时，会优先使用11来把w降到4；但是在这个问题中，凑出4的代价是很高的，必须使用4×1。如果使用了5，w会降为10，虽然没有4那么小，但是凑出10只需要两张5元。 在这里我们发现，贪心是一种只考虑眼前情况的策略。 那么，现在我们怎样才能避免鼠目寸光呢？ 如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质。 重新分析刚刚的例子。w=15时，我们如果取11，接下来就面对w=4的情况；如果取5，则接下来面对w=10的情况。我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”接下来，我们用f(n)来表示“凑出n所需的最少钞票数量”。 那么，如果我们取了11，最后的代价（用掉的钞票总数）是多少呢？ 明显 $\text{cost} = f(4) + 1 = 4 + 1 = 5$，它的意义是：利用11来凑出15，付出的代价等于f(4)加上自己这一张钞票。现在我们暂时不管f(4)怎么求出来。 依次类推，马上可以知道：如果我们用5来凑出15，cost就是 $f(10) + 1 = 2 + 1 = 3$ 。 那么，现在w=15的时候，我们该取那种钞票呢？当然是各种方案中，cost值最低的那一个！ 取11：$\text{cost}=f(4)+1=4+1=5$ 取5： $\text{cost}=f(10)+1=2+1=3$ 取1： $\text{cost}=f(14)+1=4+1=5$ 显而易见，cost值最低的是取5的方案。我们通过上面三个式子，做出了正确的决策！ 这给了我们一个至关重要的启示—— $f(n)$ 只与 $f(n-1), f(n-5), f(n-11)$ 相关；更确切地说：$f(n)=\min{f(n-1),f(n-5),f(n-11)}+1$ 这个式子是非常激动人心的。我们要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来不就好了？注意一下边界情况即可。代码如下： 我们以 $O(n)$ 的复杂度解决了这个问题。现在回过头来，我们看看它的原理： $f(n)$ 只与 $f(n-1), f(n-5), f(n-11)$ 的值相关。 我们只关心 $f(w)$ 的值，不关心是怎么凑出 w 的。 这两个事实，保证了我们做法的正确性。它比起贪心策略，会分别算出取1、5、11的代价，从而做出一个正确决策，这样就避免掉了“鼠目寸光”！ 它与暴力的区别在哪里？我们的暴力枚举了“使用的硬币”，然而这属于冗余信息。我们要的是答案，根本不关心这个答案是怎么凑出来的。譬如，要求出f(15)，只需要知道f(14),f(10),f(4)的值。**其他信息并不需要。**我们舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n). 我们能这样干，取决于问题的性质：求出 $f(n)$，只需要知道几个更小的 $f( c )$。我们将求解 $f( c )$ 称作求解 $f(n)$ 的“子问题”。 这就是DP（动态规划，dynamic programming）. 将一个问题拆成几个子问题，分别求解这些子问题，即可推断出大问题的解。 思考题：请稍微修改代码，输出我们凑出w的方案 2. 几个简单的概念 【无后效性】 一旦f(n)确定，“我们如何凑出f(n)”就再也用不着了。 要求出f(15)，只需要知道f(14),f(10),f(4)的值，而f(14),f(10),f(4)是如何算出来的，对之后的问题没有影响。 “未来与过去无关”，这就是无后效性。 （严格定义：如果给定某一阶段的状态，则在这一阶段以后过程的发展不受这阶段以前各段状态的影响。） 【最优子结构】 回顾我们对f(n)的定义：我们记“凑出n所需的最少钞票数量”为f(n). f(n)的定义就已经蕴含了“最优”。利用w=14,10,4的最优解，我们即可算出w=15的最优解。 大问题的最优解可以由小问题的最优解推出，这个性质叫做“最优子结构性质”。 引入这两个概念之后，我们如何判断一个问题能否使用DP解决呢？ 能将大问题拆成几个小问题，且满足无后效性、最优子结构性质。 3. DP的典型应用：DAG最短路 问题很简单：给定一个城市的地图，所有的道路都是单行道，而且不会构成环。每条道路都有过路费，问您从S点到T点花费的最少费用。 ​ 这个问题能用DP解决吗？我们先试着记从S到P的最少费用为 $f( P )$. 想要到T，要么经过C，要么经过D。从而 $f(T)=\min⁡ { f( C )+20,f(D)+10 }​$. 好像看起来可以DP。现在我们检验刚刚那两个性质： - 无后效性：对于点P，一旦f§确定，以后就只关心f§的值，不关心怎么去的。 - 最优子结构：对于P，我们当然只关心到P的最小费用，即f§。如果我们从S走到T是 $S \to P\to Q\to T​$ ，那肯定S走到Q的最优路径是 $S\to P\to Q​$ 。对一条最优的路径而言，从S走到**沿途上所有的点（子问题）**的最优路径，都是这条大路的一部分。这个问题的最优子结构性质是显然的。 既然这两个性质都满足，那么本题可以DP。式子明显为： $f( P )=\min⁡{f( R )+w_{R→P}}$ 其中R为有路通到P的所有的点， $w_{R→P}​$ 为R到P的过路费。 代码实现也很简单，拓扑排序即可。 4. 对DP原理的一点讨论 【DP的核心思想】 DP为什么会快？ 无论是DP还是暴力，我们的算法都是在可能解空间内，寻找最优解。 来看钞票问题。暴力做法是枚举所有的可能解，这是最大的可能解空间。 DP是枚举有希望成为答案的解。这个空间比暴力的小得多。 也就是说：DP自带剪枝。 DP舍弃了一大堆不可能成为最优解的答案。譬如： 15 = 5+5+5 被考虑了。 15 = 5+5+1+1+1+1+1 从来没有考虑过，因为这不可能成为最优解。 从而我们可以得到DP的核心思想：尽量缩小可能解空间。 在暴力算法中，可能解空间往往是指数级的大小；如果我们采用DP，那么有可能把解空间的大小降到多项式级。 一般来说，解空间越小，寻找解就越快。这样就完成了优化。 【DP的操作过程】 一言以蔽之：大事化小，小事化了。 将一个大问题转化成几个小问题； 求解小问题； 推出大问题的解。 【如何设计DP算法】 下面介绍比较通用的设计DP算法的步骤。 首先，把我们面对的局面表示为x。这一步称为设计状态。 对于状态x，记我们要求出的答案(e.g. 最小费用)为f(x).我们的目标是求出f(T). ​ 找出f(x)与哪些局面有关（记为p），写出一个式子（称为状态转移方程），通过f§来推出f(x). 【DP三连】 设计DP算法，往往可以遵循DP三连： 我是谁？ ——设计状态，表示局面 我从哪里来？ 我要到哪里去？ ——设计转移 设计状态是DP的基础。接下来的设计转移，有两种方式：一种是考虑我从哪里来（本文之前提到的两个例子，都是在考虑“我从哪里来”）；另一种是考虑我到哪里去，这常见于求出f(x)之后，更新能从x走到的一些解。这种DP也是不少的，我们以后会遇到。 总而言之，“我从哪里来”和“我要到哪里去”只需要考虑清楚其中一个，就能设计出状态转移方程，从而写代码求解问题。前者又称pull型的转移，后者又称push型的转移。（这两个词是 @阮止雨妹妹告诉我的，不知道源出处在哪） 思考题：如何把钞票问题的代码改写成“我到哪里去”的形式？ 提示：求出f(x)之后，更新f(x+1),f(x+5),f(x+11). 5. 例题：最长上升子序列 扯了这么多形而上的内容，还是做一道例题吧。 最长上升子序列（LIS）问题：给定长度为n的序列a，从a中抽取出一个子序列，这个子序列需要单调递增。问最长的上升子序列（LIS）的长度。 e.g. 1,5,3,4,6,9,7,8的LIS为1,3,4,6,7,8，长度为6。 如何设计状态（我是谁）？ 我们记 $f(x)$ 为以 $a_x$ 结尾的LIS长度，那么答案就是 $\max { f(x)}$ . 状态x从哪里推过来（我从哪里来）？ 考虑比x小的每一个p：如果 $a_x&gt;a_p​$ ，那么f(x)可以取f§+1. 解释：我们把 $a_x​$ 接在 $a_p​$ 的后面，肯定能构造一个以 $a_x​$ 结尾的上升子序列，长度比以 $a_p​$ 结尾的LIS大1.那么，我们可以写出状态转移方程了： $f(x)=\max_{p&lt;x , a_p&lt;a_x }⁡{f( p )}+1​$ 至此解决问题。两层for循环，复杂度 $O(n^2)​$ . 从这三个例题中可以看出，DP是一种思想，一种“大事化小，小事化了”的思想。带着这种思想，DP将会成为我们解决问题的利器。 最后，我们一起念一遍DP三连吧——我是谁？我从哪里来？我要到哪里去？ 6. 习题 如果读者有兴趣，可以试着完成下面几个习题： 一、请采取一些优化手段，以 $O(n\log n)$ 的复杂度解决LIS问题。 提示：可以参考这篇博客 Junior Dynamic Programming–动态规划初步·各种子序列问题 二、“按顺序递推”和“记忆化搜索”是实现DP的两种方式。请查阅资料，简单描述“记忆化搜索”是什么。并采用记忆化搜索写出钞票问题的代码，然后完成P1541 乌龟棋 - 洛谷 。 三、01背包问题是一种常见的DP模型。请完成P1048 采药 - 洛谷。 作者：王勐 链接：https://www.zhihu.com/question/23995189/answer/35429905 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 动态规划的本质不在于是递推或是递归，也不需要纠结是不是内存换时间。 理解动态规划并不需要数学公式介入，只是完全解释清楚需要点篇幅…首先需要明白哪些问题不是动态规划可以解决的，才能明白为神马需要动态规划。不过好处时顺便也就搞明白了递推贪心搜索和动规之间有什么关系，以及帮助那些总是把动规当成搜索解的同学建立动规的思路。当然熟悉了之后可以直接根据问题的描述得到思路，如果有需要的话再补充吧。 动态规划是对于 某一类问题 的解决方法！！重点在于如何鉴定“某一类问题”是动态规划可解的而不是纠结解决方法是递归还是递推！ 怎么鉴定dp可解的一类问题需要从计算机是怎么工作的说起…计算机的本质是一个状态机，内存里存储的所有数据构成了当前的状态，CPU只能利用当前的状态计算出下一个状态（不要纠结硬盘之类的外部存储，就算考虑他们也只是扩大了状态的存储容量而已，并不能改变下一个状态只能从当前状态计算出来这一条铁律） 当你企图使用计算机解决一个问题是，其实就是在思考如何将这个问题表达成状态（用哪些变量存储哪些数据）以及如何在状态中转移（怎样根据一些变量计算出另一些变量）。所以所谓的空间复杂度就是为了支持你的计算所必需存储的状态最多有多少，所谓时间复杂度就是从初始状态到达最终状态中间需要多少步！ 太抽象了还是举个例子吧： 比如说我想计算第100个非波那契数，每一个非波那契数就是这个问题的一个状态，每求一个新数字只需要之前的两个状态。所以同一个时刻，最多只需要保存两个状态，空间复杂度就是常数；每计算一个新状态所需要的时间也是常数且状态是线性递增的，所以时间复杂度也是线性的。 上面这种状态计算很直接，只需要依照固定的模式从旧状态计算出新状态就行（a[i]=a[i-1]+a[i-2]），不需要考虑是不是需要更多的状态，也不需要选择哪些旧状态来计算新状态。对于这样的解法，我们叫递推。 非波那契那个例子过于简单，以至于让人忽视了阶段的概念，所谓阶段是指随着问题的解决，在同一个时刻可能会得到的不同状态的集合。非波那契数列中，每一步会计算得到一个新数字，所以每个阶段只有一个状态。想象另外一个问题情景，假如把你放在一个围棋棋盘上的某一点，你每一步只能走一格，因为你可以东南西北随便走，所以你当你同样走四步可能会处于很多个不同的位置。从头开始走了几步就是第几个阶段，走了n步可能处于的位置称为一个状态，走了这n步所有可能到达的位置的集合就是这个阶段下所有可能的状态。 现在问题来了，有了阶段之后，计算新状态可能会遇到各种奇葩的情况，针对不同的情况，就需要不同的算法，下面就分情况来说明一下： 假如问题有n个阶段，每个阶段都有多个状态，不同阶段的状态数不必相同，一个阶段的一个状态可以得到下个阶段的所有状态中的几个。那我们要计算出最终阶段的状态数自然要经历之前每个阶段的某些状态。 好消息是，有时候我们并不需要真的计算所有状态，比如这样一个弱智的棋盘问题：从棋盘的左上角到达右下角最短需要几步。答案很显然，用这样一个弱智的问题是为了帮助我们理解阶段和状态。某个阶段确实可以有多个状态，正如这个问题中走n步可以走到很多位置一样。但是同样n步中，有哪些位置可以让我们在第n+1步中走的最远呢？没错，正是第n步中走的最远的位置。换成一句熟悉话叫做“下一步最优是从当前最优得到的”。所以为了计算最终的最优值，只需要存储每一步的最优值即可，解决符合这种性质的问题的算法就叫贪心。如果只看最优状态之间的计算过程是不是和非波那契数列的计算很像？所以计算的方法是递推。 既然问题都是可以划分成阶段和状态的。这样一来我们一下子解决了一大类问题：一个阶段的最优可以由前一个阶段的最优得到。 如果一个阶段的最优无法用前一个阶段的最优得到呢？ 什么你说只需要之前两个阶段就可以得到当前最优？那跟只用之前一个阶段并没有本质区别。最麻烦的情况在于你需要之前所有的情况才行。 再来一个迷宫的例子。在计算从起点到终点的最短路线时，你不能只保存当前阶段的状态，因为题目要求你最短，所以你必须知道之前走过的所有位置。因为即便你当前再的位置不变，之前的路线不同会影响你的之后走的路线。这时你需要保存的是之前每个阶段所经历的那个状态，根据这些信息才能计算出下一个状态！ 每个阶段的状态或许不多，但是每个状态都可以转移到下一阶段的多个状态，所以解的复杂度就是指数的，因此时间复杂度也是指数的。哦哦，刚刚提到的之前的路线会影响到下一步的选择，这个令人不开心的情况就叫做有后效性。 刚刚的情况实在太普遍，解决方法实在太暴力，有没有哪些情况可以避免如此的暴力呢？ 契机就在于后效性。 有一类问题，看似需要之前所有的状态，其实不用。不妨也是拿最长上升子序列的例子来说明为什么他不必需要暴力搜索，进而引出动态规划的思路。 假装我们年幼无知想用搜索去寻找最长上升子序列。怎么搜索呢？需要从头到尾依次枚举是否选择当前的数字，每选定一个数字就要去看看是不是满足“上升”的性质，这里第i个阶段就是去思考是否要选择第i个数，第i个阶段有两个状态，分别是选和不选。哈哈，依稀出现了刚刚迷宫找路的影子！咦慢着，每次当我决定要选择当前数字的时候，只需要和之前选定的一个数字比较就行了！这是和之前迷宫问题的本质不同！这就可以纵容我们不需要记录之前所有的状态啊！既然我们的选择已经不受之前状态的组合的影响了，那时间复杂度自然也不是指数的了啊！虽然我们不在乎某序列之前都是什么元素，但我们还是需要这个序列的长度的。所以我们只需要记录以某个元素结尾的LIS长度就好！因此第i个阶段的最优解只是由前i-1个阶段的最优解得到的，然后就得到了DP方程（感谢 @韩曦 指正） $$ LIS(i)=max{LIS(j)+1} \ \ \ \ j&lt;i \ and\ a[j] &lt; a[i] $$ 所以一个问题是该用递推、贪心、搜索还是动态规划，完全是由这个问题本身阶段间状态的转移方式决定的！ 每个阶段只有一个状态-&gt;递推； 每个阶段的最优状态都是由上一个阶段的最优状态得到的-&gt;贪心； 每个阶段的最优状态是由之前所有阶段的状态的组合得到的-&gt;搜索； 每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到而不管之前这个状态是如何得到的-&gt;动态规划。 每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到 这个性质叫做最优子结构； 而不管之前这个状态是如何得到的 这个性质叫做无后效性。 另：其实动态规划中的最优状态的说法容易产生误导，以为只需要计算最优状态就好，LIS问题确实如此，转移时只用到了每个阶段“选”的状态。但实际上有的问题往往需要对每个阶段的所有状态都算出一个最优值，然后根据这些最优值再来找最优状态。比如背包问题就需要对前i个包（阶段）容量为j时（状态）计算出最大价值。然后在最后一个阶段中的所有状态种找到最优值。 作者：阮行止 链接：https://www.zhihu.com/question/23995189/answer/613096905 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch 的 dataloader 如何读取变长数据]]></title>
    <url>%2F2019%2F04%2F03%2Fpytorch-dataloader-load-different-length-data%2F</url>
    <content type="text"><![CDATA[最近在做一个新的声学模型，其中遇到一个点就是每个sentence的长度不一样的花，直接用dataloader的读取是有问题的。查了下中文资料，大家大多数这个问题都是趋于用torch.nn.utils.rnn.PackedSequence来打包的，这个在dataloader里面其实就不太适用，pytorch论坛上提到用dataloader的collate_fn来处理的，所以想写个资料总结下 。 pytorch里面dataset的工作逻辑： pytorch的数据载入主要是这么几个逻辑，从底层一步步来讲，我用h5矩阵，图片和音频三个方面来举例，首先是逻辑层次是，首先把data装进用torch.utils.data.Dataset装进一个dataset的对象里面，然后在把dataset这个对象传递给一个torch.utils.data.DataLoader dataset的工作逻辑 数据集的切分一般在dataset这个对象上做处理，支持随机切分等，详见torch.utils.data - PyTorch master documentation，一般来讲，我都是写一个torch.utils.data.Dataset的子类，里面就三个成员函数，初始化，长度和读取，一般在读取你自己定义的读取方法，我习惯的是h5矩阵的话，就读一段（子矩阵），图片就是一张图，或者一段音频。 这里面有个很关键的点，就是dataset的逻辑是一次读一个item，最好不要在dataset层面一次slice一段，slice这个层面的事情交给dataloader来做，原因我一会说。 记住dataset的逻辑在于装和item读取，预处理，其他都不要做。 dataloader的工作逻辑 dataloader层面主要就是slice读取数据，shuffle也是在这个层面来做。 dataloader有几个关键点，很多地方都零零碎碎的提到过，我总结下， 是稀松平常的batch_size, sampler, shuffle这几个稀松平常的不提，shuffle是在dataset的item层面做混洗， 注意，num_workers是一个多线程的读取，当batchsize&gt;1的时候，多线程读取item, 然后各个item调用一个collate_fn合并成新的tensor，其中h5依然是个坑，anaconda安装的h5是不支持多线程的，请参考并行 HDF5 和 h5py安装并行h5，至于num*_*worker以及pin_memoru的具体使用，参考云梦：Pytorch 提速指南，不重复造轮子。 关于这个collate\fn是重点，当开启多线程了一个，多线程先后读取了dataset里面batch_size个item以后，生成了一个list,里面每个元素就是batchsize个item，然后用collatefn合并，如果没有指定的collatefns的话，就直接合并成一个高一维的tensor。 collatefns的工作逻辑 coolatefns的输入是个list，长度为batchsize，其中各个元素是各个item，函数的目的就是合并。 当各个item变长时，不指定collatefns合并就会报错，懒人方法就是把在dataset里面的读取函数把tensor加到最长，就可以直接merge。 当使用collatefns时，pytorch论坛上有人写了一个函数，我贴过来，大家配合注释看看： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def pad_tensor(vec, pad, dim): """ args: vec - tensor to pad pad - the size to pad to dim - dimension to pad return: a new tensor padded to 'pad' in dimension 'dim' """ pad_size = list(vec.shape) pad_size[dim] = pad - vec.size(dim) return torch.cat([vec, torch.zeros(*pad_size)], dim=dim)class PadCollate: """ a variant of callate_fn that pads according to the longest sequence in a batch of sequences """ def __init__(self, dim=0): """ args: dim - the dimension to be padded (dimension of time in sequences) """ self.dim = dim def pad_collate(self, batch): """ args: batch - list of (tensor, label) reutrn: xs - a tensor of all examples in 'batch' after padding ys - a LongTensor of all labels in batch """ # find longest sequence max_len = max(map(lambda x: x[0].shape[self.dim], batch)) # pad according to max_len batch = map(lambda (x, y): (pad_tensor(x, pad=max_len, dim=self.dim), y), batch) # stack all xs = torch.stack(map(lambda x: x[0], batch), dim=0) ys = torch.LongTensor(map(lambda x: x[1], batch)) return xs, ys def __call__(self, batch): return self.pad_collate(batch) 调用使用： 1train_loader = DataLoader(ds, ..., collate_fn=PadCollate(dim=0)) 来源：DataLoader for various length of data 对于读取了以后的数据，在rnn中的工作逻辑，pytorch的文档也提到过 total_length is useful to implement the packsequence-&gt;recurrentnetwork-&gt;unpacksequence pattern in a Module wrapped in DataParallel. See this FAQ sectionfor details. 来源：torch.nn - PyTorch master documentation 关于读取到了的padding的变长数据，如何pack，请参考 @尹相楠 的： 尹相楠：PyTorch 训练 RNN 时，序列长度不固定怎么办？ 本文转载自 知乎 Charlie的语音处理实验室 原文链接：https://zhuanlan.zhihu.com/p/60129684]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】 腾讯算法实习面经]]></title>
    <url>%2F2019%2F04%2F03%2Frepost-tencent-intern-interview-summary%2F</url>
    <content type="text"><![CDATA[牛客网 腾讯算法实习面试总结—论面试官虐我的一百种方式]]></content>
      <categories>
        <category>求职</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git 使用笔记]]></title>
    <url>%2F2019%2F04%2F03%2Fgit-note%2F</url>
    <content type="text"><![CDATA[廖雪峰的 Git 教程 少用 Pull 多用 Fetch 和 Merge 见到很多人说过这个经验，原因就是 git pull 把过程的细节都隐藏了起来，大部分时候是没有问题的，但是当代码出错时可能会造成损失。很多时候我们宁愿做的慢一些，也不愿意返工重来 一般的做法是： 12git fetch origin # 下载远程分支的更新git merge origin/master # 合并远程分支到当前分支 如果你想在合并前查看本地分支和远程分支的差异，可以使用下面的命令： 1git diff master origin/master 单独进行下载和合并是一个好的做法，你可以先看看下载的是什么，然后再决定是否和本地代码合并，方便使用。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nvcc 编译报错：找不到 "cuda_runtime.h"]]></title>
    <url>%2F2019%2F04%2F02%2Fnvcc-fatal-error-cuda-runtime-h%2F</url>
    <content type="text"><![CDATA[奇怪的错误 今天在安装 PANet 时遇到了一个奇怪的错误： 12Compiling nms kernels by nvcc...cc1plus: fatal error: cuda_runtime.h: No such file or directory 按理说不应该出现这种奇怪的错误，cuda_runtime.h 就安静地躺在 /usr/local/cuda/include 目录下，cuda 安装是没有问题的，这个仓库在实验室的服务器上也跑过，完全没有问题。然而就是这样的错误费了老半天时间也无法定位原因，网上的解决办法无非就是环境变量的问题，多次确认之后环境变量是没有问题的 😩 难道要因为这个错误重装 cuda？ 重装是不太可能的，服务器上配环境太费事， 于是查看 nvcc 命令帮助，果然其中写着可以用 -I 选项指定包含头文件的路径，迅速在 PANet/lib/make.sh 中有关 nvcc 的命令加上 -I /usr/local/cuda/include ，运行，成功 😎 估计是环境变量出现了某种错误，虽然到最后也没有搞明白为什么会出现这个错误，但好歹是解决了这个问题。这个问题说明了遇事不能只靠百度，要自己好好分析]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过 SSH 隧道连接远程服务器的 Jupyter Notebook]]></title>
    <url>%2F2019%2F02%2F24%2FRemote-jupyter-notebook%2F</url>
    <content type="text"><![CDATA[参考: https://www.howtoing.com/how-to-install-run-connect-to-jupyter-notebook-on-remote-server 在远程服务器上没有安装浏览器的情况下，通过在本地建立 SSH 隧道的方法使用服务器的 Jupyter Notebook 1. 服务器端 首先确保服务器端安装了 Jupyter Notebook，如果需要使用 conda 环境，还要安装 ipykernel 等包 进入虚拟环境，运行 Jupyter Notebook 1jupyter notebook 根据输出的信息可以看到无法找到可用的浏览器 12345[I 09:56:37.551 NotebookApp] Serving notebooks from local directory: /home/liuxiangyu[I 09:56:37.551 NotebookApp] The Jupyter Notebook is running at:[I 09:56:37.552 NotebookApp] http://172.17.0.2:8888/?token=******[I 09:56:37.552 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[W 09:56:37.557 NotebookApp] No web browser found: could not locate runnable browser. 注意：如果报错信息提示地址已经被占用，那么久需要修改一下 Jupyter Notebook 的默认地址。修改方式如下： 配置 Jupyter Notebook 1jupyter notebook --generate-config 运行命令后将会在主目录下生成 .jupyter/jupyter_notebook_config.py 文件，打开文件找到 #c.NotebookApp.ip = 'localhost'，把 # 号去掉，localhost 改成自己的 ip 地址（在上面输出信息中可以看到） 保存后关闭文件，重启 Jupyter Notebook 即可 至此，服务器端的准备已经完成了，我们需要记住服务器的地址 172.17.0.2 和端口号 8008 2. 本地 以 Windows 系统为例，下载 putty 打开 putty 后在服务器地址和端口处正确填写信息，然后在左侧 ssh 选项下选择 Tunnels Source port 填写本地想用的端口号，以 8000 为例 Destination 填写 服务器地址 172.17.0.2:8888 其他选项不要修改，最后不要忘记点击 Add，然后连接即可 连接到服务器后进入相应的虚拟环境，运行 Jupyter Notebook，然后打开浏览器输入地址 https://localhost:8000 即可打开 notebook. 第一次进入 notebook 可能需要输入 token，按照提示输入相应的 token 即可 Done! 😎]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>env</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Detectron 安装步骤]]></title>
    <url>%2F2019%2F01%2F20%2Fdetectron-installation%2F</url>
    <content type="text"><![CDATA[Requirements： Linux 16.04, Python2, NVIDIA GPU (Detectron 目前只有 GPU 版本) CUDA 9.0, cuDNN7.0.5 Caffe2, COCO API 为保持 Python 环境的独立性与完整性，安装前新建一个新的虚拟环境，以下安装过程在虚拟环境中进行 123# 在主环境下conda create -n detectron python=2.7source activate detectron [TOC] CUDA &amp; cuDNN 安装 CUDA9.0 和 cuDNN7.0.5，具体安装步骤参考英伟达官网 Caffe2 1. 从源码编译 以下为源码编译的过程，尝试过安装 Pre-Built Binaries，结果失败了，也可以直接安装预编译文件（推荐），[2. 安装预编译文件](#2. 安装预编译文件) 安装依赖包 1234567891011121314151617181920212223242526sudo apt-get updatesudo apt-get install -y --no-install-recommends \ build-essential \ git \ libgoogle-glog-dev \ libgtest-dev \ libiomp-dev \ libleveldb-dev \ liblmdb-dev \ libopencv-dev \ libopenmpi-dev \ libsnappy-dev \ libprotobuf-dev \ openmpi-bin \ openmpi-doc \ protobuf-compiler \ python-dev \ python-pip \ libgflags-dev \ cmakepip install --user \ future \ numpy \ protobuf \ typing \ hypothesis pip install 使用默认镜像下载速度较慢，可以选择使用清华大学 pypi 镜像 123456# for temporary usepip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package# set to defaultpip install pip -U # upgrade pip to the latest version (&gt;=10.0.0)pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 下载代码仓库并编译 1234git clone https://github.com/pytorch/pytorch.git &amp;&amp; cd pytorchgit submodule update --init --recursive # 安装所需子模块conda install pyyaml # 安装缺少的依赖包python setup.py install 如果编译顺利通过，恭喜，接下来测试 caffe2 安装是否正确，[3. 安装后测试](#3. 安装后测试) 错误信息1：服务器安装的 git 在执行 clone 命令时报错找不到 https 协议，应该是安装不完整导致的，可以在当前环境下重新安装 git 后重试（使用命令 conda install git，推荐）或者使用以下命令代替： 1git clone git://github.com/pytorch/pytorch.git &amp;&amp; cd pytorch 错误信息2（未解决）：在执行安装命令时 (python setup.py install)，出现以下错误： 1······/libmklml_intel.so: file not recognized: File truncated. 该错误指向 pytorch/third_party/ideep/mkl-dnn/external/mklml_lnx_2019.0.1.20180928/lib/libmklml_intel.so 文件，可能是文件不完整导致的错误，但是未找到原因及解决方法。如果出现此错误请尝试通过预编译文件安装 caffe2. 其他错误：查看 Caffe2 troubleshooting 2. 安装预编译文件 Caffe2 只提供 Anaconda 的预编译安装包，需要安装 Anaconda 或 Miniconda 首先添加清华大学维护的 PyTorch 源，下载速度更快： 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 然后执行安装操作： 1conda install pytorch-nightly 3. 安装后测试 安装完成后，测试安装是否成功 123456# To check if Caffe2 build was successfulpython -c 'from caffe2.python import core' 2&gt;/dev/null &amp;&amp; echo "Success" || echo "Failure"# To check if Caffe2 GPU build was successful# This must print a number &gt; 0 in order to use Detectronpython -c 'from caffe2.python import workspace; print(workspace.NumCudaDevices())' 根据执行结果判断安装是否成功 从源码编译需注意： If the caffe2 Python package is not found, you likely need to adjust your PYTHONPATH environment variable to include its location (/path/to/caffe2/build, where build is the Caffe2 CMake build directory). COCO API 依赖： setuptools&gt;=18.0 cython&gt;=0.27.3 matplotlib&gt;=2.1.0 123456conda install setuptools cython matplotlibCOCOAPI=/path/to/clone/cocoapi # 指定安装路径git clone https://github.com/cocodataset/cocoapi.git $COCOAPIcd $COCOAPI/PythonAPImake#python setup.py install --user Detectron 下载代码仓库： 12DETECTRON=/path/to/clone/detectron # 指定安装路径git clone https://github.com/facebookresearch/detectron $DETECTRON 安装 Python 依赖： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r $DETECTRON/requirements.txt 然后 make: 1cd $DETECTRON &amp;&amp; make 安装完成后运行测试： 1python $DETECTRON/detectron/tests/test_spatial_narrow_as_op.py 结果输出 OK，安装完毕 输出以下提示信息不必理会： 12No handlers could be found for logger "caffe2.python.net_drawer"net_drawer will not run correctly. Please install the correct dependencies. Troubleshooting 参照 Detectron Troubleshooting Reference https://github.com/facebookresearch/Detectron/blob/master/INSTALL.md https://caffe2.ai/docs/getting-started.html?platform=ubuntu&amp;configuration=prebuilt https://blog.csdn.net/weixin_43624538/article/details/84712617 P.S. CUDA8.0 cuDNN5.1.10 安装失败，原因：PyTorch 需要 cuDNN&gt;=7.0 查看 CUDA 和 cuDNN 版本： 12345# CUDAcat /usr/local/cuda/version.txt# cuDNNcat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2]]></content>
      <categories>
        <category>安装</category>
      </categories>
      <tags>
        <tag>detectron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YOLOv3 安装步骤]]></title>
    <url>%2F2019%2F01%2F15%2FYOLOv3-installation%2F</url>
    <content type="text"><![CDATA[操作系统：Linux 16.04 依赖： CUDA OpenCV darknet 写在前面：conda 是一款非常好用的 python 环境管理工具，建议安装 Anaconda 或 Miniconda。安装及使用请参阅网上教程，安装完成后记得添加清华大学 tuna 镜像。 Anaconda 镜像使用帮助 CUDA 按照网上教程或英伟达官方网站正确安装 CUDA 和 cuDNN（实验室服务器上的版本是 cuda9.0 cudnn7.1） OpenCv 如果安装了 conda，首先进入你想要安装 YOLO 的虚拟环境。第一次使用 Anaconda 请先创建虚拟环境。 1conda create --name YOURNAME python=3.6 numpy pandas matplotlib （YOURNAME 替换为你想要的名字）上述命令将创建新的 python 虚拟环境，并安装常用工具包 numpy, pandas, matplotlib，创建完成后进入虚拟环境 12source activate YOURNAMEsource deactivate # use this one to exit 进入环境后开始安装 OpenCV 1conda install opencv 安装完毕即可 darknet 首先下载 github 仓库 12git clone https://github.com/AlexeyAB/darknet.gitcd darknet 然后打开 Makefile 文件，修改以下选项： 123GPU = 1CUDNN = 1OPENCV = 1 然后在 darknet 目录下执行 1make 如果没有报错，YOLOv3 就安装成功了。测试一下 1./darknet 可以看到输出为： 1usage: ./darknet &lt;function&gt; Reference https://github.com/AlexeyAB/darknet https://pjreddie.com/darknet/yolo/ 🦄]]></content>
      <categories>
        <category>安装</category>
      </categories>
      <tags>
        <tag>yolo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PANet 安装步骤]]></title>
    <url>%2F2019%2F01%2F15%2FPANet-installation%2F</url>
    <content type="text"><![CDATA[Requirements 操作系统：Linux 16.04 平台：PyTorch 依赖 pytorch = 0.4.0 torchvision &gt;= 0.2.0 cython matplotlib numpy scipy opencv pyyaml packaging pycocotools – for coco dataset tensorboardX – for logging in TensorBoard PyTorch 使用 conda 安装 PyTorch 比较简单，首先进入 conda 环境，然后执行 1conda install pytorch=0.4.0 torchvision cuda90 -c pytorch 其余 cython 等包都可以使用 conda install 或者 pip install 命令来安装，就不再重复了 编译 PANet 首先下载 github 仓库： 12git clone https://github.com/ShuLiu1993/PANet.gitcd PANet 然后编译 12cd lib # please change to this directorysh make.sh 等待编译完成即可。训练代码在 PANet/tools 文件夹下。 如果安装过程报错找不到 cuda_runtime.h，可以查看这里 Reference https://github.com/ShuLiu1993/PANet https://github.com/roytseng-tw/Detectron.pytorch]]></content>
      <categories>
        <category>安装</category>
      </categories>
      <tags>
        <tag>panet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查找回文字符串：马拉车算法 Manacher's Algorithm]]></title>
    <url>%2F2018%2F12%2F20%2FManacher-Algorithm%2F</url>
    <content type="text"><![CDATA[在 LeetCode 看到一个题，给定一个字符串，返回最大长度的回文子字符串。 Example: 12Input: "babad"Output: "bab" or "aba" 最简单的方法就是暴力循环遍历，但是算法复杂度为 $O(n^3)$, 因此记录一个线性复杂度的算法——马拉车算法。 LeetCode：https://leetcode.com/problems/longest-palindromic-substring 英文解释：https://articles.leetcode.com/longest-palindromic-substring-part-ii 中文解释：https://www.felix021.com/blog/read.php?2040 Manacher’s Algorithm 首先，假设输入字符串为 abaaba，显然输入即为最长的回文字符串，因此输出应为 abaaba。让我们分两步来解决这个问题。 1. 预处理 我们想一下可能会发现，回文字符串分为两种情况：奇数长度和偶数长度。这两种情况显然是无法直接合并处理的，因此马拉车算法首先对输入的字符串进行了一下处理：在每个字符的两侧插入一个特定字符 #，例如： 12S = &apos;abaaba&apos;T = &apos;#a#b#a#a#b#a#&apos; 这样做的好处是所有的字符串都变成了奇数长度，这样我们就不需要分别考虑了 预处理部分的代码如下： 123456def preProcess(self, s): l = [c for c in s] ret = '#'.join(l) # add ^ and $ at both bounds to avoid out of index problem return '^#'+ret+'#$' 2. 算法部分 算法的思想是这样的，对于一个预处理之后的字符串 T，定义一个具有相同长度的数组 P，使得 P[i] 等于以 T[i] 为中心的 T 中最长回文字符串的半径，对于上面的例子 12T = # a # b # a # a # b # a #P = 0 1 0 3 0 1 6 1 0 3 0 1 0 我们可以发现，P 具有某种对称性质，我们可以利用这个性质在一定程度上减小我们的计算复杂度。那么所有的情况都是对称的吗？可惜的是并不是，只有在某种特定的条件下这种情况才成立。但是没关系，我们一样可以利用这个性质减少计算，只是需要找到不满足这种情况的条件就可以了 我们来看一个稍微复杂一点的例子，S = ‘babcbabcbaccba’ 上图中假设当前 i 为 13， 实线表示回文字符串 abcbabcba的中心，虚线表示两侧的边界。我们可以看到，由于回文字符串的对称性质，我们可以快速的知道 P[13] 的值，也就是等于 P[9] 处的值。然后继续看 现在我们到了下标为 15 的位置，p[15] 的值是多少呢？如果我们继续根据对称性质，那么就会得到 P[15] = P[7] = 7，但很显然是错误的。 如果以 T[15] 为中心，我们得到的回文字符串为 #a#b#c#b#a#，而 T[7] 处的回文字符串要更长，这是因为我们当前的以 C 为中心的回文字符串并不能完全包含以 T[7] 为中心的回文字符串，因此就造成了不满足对称性质的情况。解决办法也很简单，只要取 P[i] = min(P[i'], R-i) 就可以了。 用伪代码总结一下： 123if P[i&apos;] &lt;= R - ithen P[i] = P[i&apos;]else P[i] &lt;= P[i&apos;] 然后我们需要确定 R 和 C 的更新策略：如果以 i 为中心的回文字符串的超过了 R，则令新的中心C = i，然后把 R 扩展到新的回文字符串的右边界。 全部代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution: def longestPalindrome(self, s): """ :type s: str :rtype: str """ # Manacher's algorithm T = self.preProcess(s) length = len(T) C, R = 0, 0 P = [0] * length i = 1 while i &lt; length-1: # i_mirror can reduce the computation of P[i] i_mirror = 2*C - i # equals to C - (i - C) P[i] = min(P[i_mirror], R-i) if R &gt; i else 0 # expand the palindrome centered at i while T[i + P[i] + 1] == T[i - P[i] - 1]: P[i] += 1 # adjust center if the expanded palindrome pasts R if R &lt; i + P[i]: C = i R = i + P[i] i += 1 maxLength = max(P) centerIndex = P.index(maxLength) start = (centerIndex - maxLength) // 2 stop = start + maxLength return s[start:stop] def preProcess(self, s): l = [c for c in s] ret = '#'.join(l) # add ^ and $ at both bounds to avoid out of index problem return '^#'+ret+'#$' 最后 按理说线性复杂度的算法已经是很快了，当然 LeetCode 上还有很多大神的神仙代码更快，反正我是看不懂…… 🙂 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch 调用 GPU 报 CUDA unknown error]]></title>
    <url>%2F2018%2F12%2F18%2Fpytorch-cuda-unknown-error%2F</url>
    <content type="text"><![CDATA[最近为了跑 PANet，在服务器上安装了 Detectron.pytorch，安装过程还挺顺利，但是只要调用 GPU 运算就报未知错误，网上搜索一番发现可能是显卡驱动安装有问题，导致 Torch 调用显卡时无法正常初始化。这里记录一下网上的解决方法。 报错信息 1RuntimeError: cuda runtime error (30) : unknown error at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/THCTensorRandom.cu:25 方法1：重新安装显卡驱动和 CUDA 既然是驱动问题，那么自然地重新安装一下最新版的显卡驱动应该就没问题了，注意驱动安装完成之后最好要重启一下机器。安装完驱动之后使用 conda 重新安装 PyTorch。但是由于服务器是公用资源，为了不影响同学使用，只得使用权宜之计。 方法2：root 权限运行 python 网上的解决方法除了重装驱动之外，还有一种暂时的解决办法。因为正确安装显卡驱动会保证 Torch 调用显卡时自动进行正常的初始化，那我也可以手动赋予 python root 权限去初始化显卡。 在尝试的过程中发现，由于服务器环境比较混乱，sudo 提升权限之后运行的不是我自己的 python，而且 PYTHONPATH 和 一些环境变量也不对。解决方法如下： 首先在 python 代码中加上 12345import osimport syssys.path.append('/path/to/cocoapi/PythonAPI') # my code needs pycocotoolsos.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID" # optionalos.environ["CUDA_VISIBLE_DEVICES"]="0" 然后在运行 1sudo /path/to/your/python tools/train_net_step.py --dataset dota --cfg xx.yml --use_tfboard 然后就可以开始训练了 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>cuda</tag>
        <tag>error</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译时遇到 /tmp 文件夹空间不足的解决办法]]></title>
    <url>%2F2018%2F12%2F11%2FNo-Space-in-tmp%2F</url>
    <content type="text"><![CDATA[今天在服务器上编译 PyTorch 时遇到了 /tmp 文件夹空间不足的问题，一般来说安装 Ubuntu 时给 / 挂载点分配足够的硬盘空间就不会遇到这个问题，但是服务器有很多人用，文件比较混乱，/挂载点已经达到了 100% 的空间使用率，因此百度到了一个解决办法 其实解决方法很简单，只需要在有硬盘空间的挂载点下（例如 /home ）新建一个临时文件夹供编译时临时使用就可以了 新建文件夹 在用户目录下新建临时文件夹，并使之生效即可 123cd /home/lxymkdir tmpexport TMPDIR = /home/lxy/tmp 这样重新执行编译命令就可以顺利编译了 还可以将最后一句代码写进 .bashrc 文件，然后 source 一下，以后临时文件都会存放在该临时文件夹 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将 DOTA 数据集的标注转换为 COCO 格式]]></title>
    <url>%2F2018%2F12%2F10%2FConvert-dataset-to-coco-like%2F</url>
    <content type="text"><![CDATA[DOTA 数据集：http://captain.whu.edu.cn/DOTAweb/index.html COCO 数据集：http://cocodataset.org/#download COCO API：https://github.com/cocodataset/cocoapi API make 报错，安装 Cython 即可 1conda install cython COCO 数据集简介 COCO 数据集包含 instance，keypoint 和 caption 等部分，本文只介绍 instance 相关内容 COCO 数据集的组织方式 coco ├── annos.txt (optional) ├── annotations ├── classes.txt (optional) └── images annotations 文件夹放数据集的标注文件（json格式），images 文件夹放数据集的所有图片，（annos.txt 放数据集的原始标注文件，class.txt 放标注的类别名称，每行一个类别，不含背景） COCO 的数据标注格式 COCO 数据集以 json 文件格式存储数据集的标注信息，标注的格式可以参考 官网 和这个 知乎专栏，在这里就不重复了。 确定了标注的格式以后，分析 DOTA 数据集的标注格式，可以提取其中的信息然后以 json 格式存储下来就可以了 格式转换脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import jsonimport dota_utils as utilimport osfrom PIL import Imageinfo = &#123;"description": "DOTA dataset from WHU", "url": "http://caption.whu.edu.cn", "year": 2018, "version": "1.0"&#125;licenses = &#123;"url": "http://creativecommons.org/licenses/by-nc/2.0/", "id": 1, "name": "Attribution-NonCommercial License"&#125;categories = []for i, catName in enumerate(util.wordname_15, start=1): categories.append(&#123;"id": i, "name": "%s" % catName, "supercategory": "%s" % catName&#125;)images = []annotations = []aug = "/home/lxy/dota/data/aug"augmented = "/home/lxy/dota/data/augmented"train_small = "/home/lxy/dota/data/train_small"trainsplit_HBB = "/home/lxy/dota/data/trainsplit_HBB"val_small = "/home/lxy/dota/data/val_small"valsplit_HBB = "/home/lxy/dota/data/valsplit_HBB"dataset_path = [augmented, train_small, trainsplit_HBB, val_small, valsplit_HBB]imgid = 0annid = 0for path in dataset_path: img_path = os.path.join(path, "images") label_path = os.path.join(path, "labelTxt") for file in os.listdir(label_path): img_name = file.replace("txt", "png") im = Image.open(os.path.join(img_path, img_name)) w, h = im.size imgid += 1 images.append(&#123;"license": 1, "file_name": "%s" % img_name, \ "height": h, "width": w, "id": imgid&#125;) f = open(os.path.join(label_path, file)) for line in f.readlines(): line = "".join(line).strip("\n").split(" ") # a bbox has 4 points, a category name and a difficulty if len(line) != 10: print(path, file) else: annid += 1 catid = util.wordname_15.index(line[-2]) + 1 w_bbox = int(line[4][:-2]) - int(line[0][:-2]) h_bbox = int(line[5][:-2]) - int(line[1][:-2]) bbox = [line[0], line[1], str(w_bbox)+'.0', str(h_bbox)+'.0'] annotations.append(&#123;"id": annid, "image_id": imgid, "category_id": catid, \ "segmentation": [line[0:8]], "area": float(w_bbox*h_bbox), \ "bbox": bbox, "iscrowd": 0&#125;) f.close()my_json = &#123;"info": info, "licenses": licenses, "images": images, "annotations": annotations, "categories": categories&#125;with open("/home/lxy/dota/data/coco/annotations/train.json", "w+") as f: json.dump(my_json, f) print("writing json file done!") 检查转换结果 这里需要用到 COCO API，具体用法参考 repo 里的 demo 文件，读取转换完成的数据集并显示标注结果，观察标注是否有误 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>数据集</tag>
        <tag>COCO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NP-Hard问题]]></title>
    <url>%2F2018%2F12%2F07%2FNP-Hard%2F</url>
    <content type="text"><![CDATA[简单理解 NP, P, NP-Complete 和 NP-Hard 参考：https://www.cnblogs.com/sancyun/p/4250360.html P 是一类可以通过确定性图灵机（以下简称 图灵机）在多项式时间 (Polynomial time) 内解决的问题集合。 NP 是一类可以通过非确定性图灵机 ( Non-deterministic Turing Machine) 在多项式时间 (Polynomial time) 内解决的决策问题集合。 P 是 NP 的子集，也就是说任何可以被图灵机在多项式时间内解决的问题都可以被非确定性的图灵机解决。 接下来说说 NP 里最难得问题 NP-Complete。 其定义如下， 如果一个决策问题 L 是 NP-Complete 的，那么 L 具备以下两个性质： L 是 NP（给定一个解决 NP-Complete 的方案 (solution，感兴趣的读者可以思考一下 solution 和 answer 的区别)，可以很快验证是否可行，但不存在已知高效的方案 。） NP 里的任何问题可以在多项式时间内转为 L。 而 NP-Hard 只需要具备 NP-Complete 的第二个性质，因此 NP-Complete 是 NP-Hard 的子集。 这四者的关系如下图（假设 P!= NP）：]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>NP-Hard</tag>
      </tags>
  </entry>
</search>
