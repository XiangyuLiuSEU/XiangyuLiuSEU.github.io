<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[通过 SSH 隧道连接远程服务器的 Jupyter Notebook]]></title>
    <url>%2F2019%2F02%2F24%2FRemote-jupyter-notebook%2F</url>
    <content type="text"><![CDATA[参考: https://www.howtoing.com/how-to-install-run-connect-to-jupyter-notebook-on-remote-server 在远程服务器上没有安装浏览器的情况下，通过在本地建立 SSH 隧道的方法使用服务器的 Jupyter Notebook 1. 服务器端 首先确保服务器端安装了 Jupyter Notebook，如果需要使用 conda 环境，还要安装 ipykernel 等包 进入虚拟环境，运行 Jupyter Notebook 1jupyter notebook 根据输出的信息可以看到无法找到可用的浏览器 12345[I 09:56:37.551 NotebookApp] Serving notebooks from local directory: /home/liuxiangyu[I 09:56:37.551 NotebookApp] The Jupyter Notebook is running at:[I 09:56:37.552 NotebookApp] http://172.17.0.2:8888/?token=******[I 09:56:37.552 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[W 09:56:37.557 NotebookApp] No web browser found: could not locate runnable browser. 注意：如果报错信息提示地址已经被占用，那么久需要修改一下 Jupyter Notebook 的默认地址。修改方式如下： 配置 Jupyter Notebook 1jupyter notebook --generate-config 运行命令后将会在主目录下生成 .jupyter/jupyter_notebook_config.py 文件，打开文件找到 #c.NotebookApp.ip = 'localhost'，把 # 号去掉，localhost 改成自己的 ip 地址（在上面输出信息中可以看到） 保存后关闭文件，重启 Jupyter Notebook 即可 至此，服务器端的准备已经完成了，我们需要记住服务器的地址 172.17.0.2 和端口号 8008 2. 本地 以 Windows 系统为例，下载 putty 打开 putty 后在服务器地址和端口处正确填写信息，然后在左侧 ssh 选项下选择 Tunnels Source port 填写本地想用的端口号，以 8000 为例 Destination 填写 服务器地址 172.17.0.2:8008 其他选项不要修改，最后不要忘记点击 Add，然后连接即可 连接到服务器后进入相应的虚拟环境，运行 Jupyter Notebook，然后打开浏览器输入地址 https://localhost:8000 即可打开 notebook Done! 😎]]></content>
      <categories>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[查找回文字符串：马拉车算法 Manacher's Algorithm]]></title>
    <url>%2F2018%2F12%2F20%2FManacher-Algorithm%2F</url>
    <content type="text"><![CDATA[在 LeetCode 看到一个题，给定一个字符串，返回最大长度的回文子字符串。 Example: 12Input: "babad"Output: "bab" or "aba" 最简单的方法就是暴力循环遍历，但是算法复杂度为 $O(n^3)$, 因此记录一个线性复杂度的算法——马拉车算法。 LeetCode：https://leetcode.com/problems/longest-palindromic-substring 英文解释：https://articles.leetcode.com/longest-palindromic-substring-part-ii 中文解释：https://www.felix021.com/blog/read.php?2040 Manacher’s Algorithm 首先，假设输入字符串为 abaaba，显然输入即为最长的回文字符串，因此输出应为 abaaba。让我们分两步来解决这个问题。 1. 预处理 我们想一下可能会发现，回文字符串分为两种情况：奇数长度和偶数长度。这两种情况显然是无法直接合并处理的，因此马拉车算法首先对输入的字符串进行了一下处理：在每个字符的两侧插入一个特定字符 #，例如： 12S = &apos;abaaba&apos;T = &apos;#a#b#a#a#b#a#&apos; 这样做的好处是所有的字符串都变成了奇数长度，这样我们就不需要分别考虑了 预处理部分的代码如下： 123456def preProcess(self, s): l = [c for c in s] ret = '#'.join(l) # add ^ and $ at both bounds to avoid out of index problem return '^#'+ret+'#$' 2. 算法部分 算法的思想是这样的，对于一个预处理之后的字符串 T，定义一个具有相同长度的数组 P，使得 P[i] 等于以 T[i] 为中心的 T 中最长回文字符串的半径，对于上面的例子 12T = # a # b # a # a # b # a #P = 0 1 0 3 0 1 6 1 0 3 0 1 0 我们可以发现，P 具有某种对称性质，我们可以利用这个性质在一定程度上减小我们的计算复杂度。那么所有的情况都是对称的吗？可惜的是并不是，只有在某种特定的条件下这种情况才成立。但是没关系，我们一样可以利用这个性质减少计算，只是需要找到不满足这种情况的条件就可以了 我们来看一个稍微复杂一点的例子，S = ‘babcbabcbaccba’ 上图中假设当前 i 为 13， 实线表示回文字符串 abcbabcba的中心，虚线表示两侧的边界。我们可以看到，由于回文字符串的对称性质，我们可以快速的知道 P[13] 的值，也就是等于 P[9] 处的值。然后继续看 现在我们到了下标为 15 的位置，p[15] 的值是多少呢？如果我们继续根据对称性质，那么就会得到 P[15] = P[7] = 7，但很显然是错误的。 如果以 T[15] 为中心，我们得到的回文字符串为 #a#b#c#b#a#，而 T[7] 处的回文字符串要更长，这是因为我们当前的以 C 为中心的回文字符串并不能完全包含以 T[7] 为中心的回文字符串，因此就造成了不满足对称性质的情况。解决办法也很简单，只要取 P[i] = min(P[i'], R-i) 就可以了。 用伪代码总结一下： 123if P[i&apos;] &lt;= R - ithen P[i] = P[i&apos;]else P[i] &lt;= P[i&apos;] 然后我们需要确定 R 和 C 的更新策略：如果以 i 为中心的回文字符串的超过了 R，则令新的中心C = i，然后把 R 扩展到新的回文字符串的右边界。 全部代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution: def longestPalindrome(self, s): """ :type s: str :rtype: str """ # Manacher's algorithm T = self.preProcess(s) length = len(T) C, R = 0, 0 P = [0] * length i = 1 while i &lt; length-1: # i_mirror can reduce the computation of P[i] i_mirror = 2*C - i # equals to C - (i - C) P[i] = min(P[i_mirror], R-i) if R &gt; i else 0 # expand the palindrome centered at i while T[i + P[i] + 1] == T[i - P[i] - 1]: P[i] += 1 # adjust center if the expanded palindrome pasts R if R &lt; i + P[i]: C = i R = i + P[i] i += 1 maxLength = max(P) centerIndex = P.index(maxLength) start = (centerIndex - maxLength) // 2 stop = start + maxLength return s[start:stop] def preProcess(self, s): l = [c for c in s] ret = '#'.join(l) # add ^ and $ at both bounds to avoid out of index problem return '^#'+ret+'#$' 最后 按理说线性复杂度的算法已经是很快了，当然 LeetCode 上还有很多大神的神仙代码更快，反正我是看不懂…… 🙂 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch 调用 GPU 报 CUDA unknown error]]></title>
    <url>%2F2018%2F12%2F18%2Fpytorch-cuda-unknown-error%2F</url>
    <content type="text"><![CDATA[最近为了跑 PANet，在服务器上安装了 Detectron.pytorch，安装过程还挺顺利，但是只要调用 GPU 运算就报未知错误，网上搜索一番发现可能是显卡驱动安装有问题，导致 Torch 调用显卡时无法正常初始化。这里记录一下网上的解决方法。 报错信息 1RuntimeError: cuda runtime error (30) : unknown error at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THC/THCTensorRandom.cu:25 方法1：重新安装显卡驱动和 CUDA 既然是驱动问题，那么自然地重新安装一下最新版的显卡驱动应该就没问题了，注意驱动安装完成之后最好要重启一下机器。安装完驱动之后使用 conda 重新安装 PyTorch。但是由于服务器是公用资源，为了不影响同学使用，只得使用权宜之计。 方法2：root 权限运行 python 网上的解决方法除了重装驱动之外，还有一种暂时的解决办法。因为正确安装显卡驱动会保证 Torch 调用显卡时自动进行正常的初始化，那我也可以手动赋予 python root 权限去初始化显卡。 在尝试的过程中发现，由于服务器环境比较混乱，sudo 提升权限之后运行的不是我自己的 python，而且 PYTHONPATH 和 一些环境变量也不对。解决方法如下： 首先在 python 代码中加上 12345import osimport syssys.path.append('/path/to/cocoapi/PythonAPI') # my code needs pycocotoolsos.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID" # optionalos.environ["CUDA_VISIBLE_DEVICES"]="0" 然后在运行 1sudo /path/to/your/python tools/train_net_step.py --dataset dota --cfg xx.yml --use_tfboard 然后就可以开始训练了 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>cuda</tag>
        <tag>error</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译时遇到 /tmp 文件夹空间不足的解决办法]]></title>
    <url>%2F2018%2F12%2F11%2FNo-Space-in-tmp%2F</url>
    <content type="text"><![CDATA[今天在服务器上编译 PyTorch 时遇到了 /tmp 文件夹空间不足的问题，一般来说安装 Ubuntu 时给 / 挂载点分配足够的硬盘空间就不会遇到这个问题，但是服务器有很多人用，文件比较混乱，/挂载点已经达到了 100% 的空间使用率，因此百度到了一个解决办法 其实解决方法很简单，只需要在有硬盘空间的挂载点下（例如 /home ）新建一个临时文件夹供编译时临时使用就可以了 新建文件夹 在用户目录下新建临时文件夹，并使之生效即可 123cd /home/lxymkdir tmpexport TMPDIR = /home/lxy/tmp 这样重新执行编译命令就可以顺利编译了 还可以将最后一句代码写进 .bashrc 文件，然后 source 一下，以后临时文件都会存放在该临时文件夹 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将 DOTA 数据集的标注转换为 COCO 格式]]></title>
    <url>%2F2018%2F12%2F10%2FConvert-dataset-to-coco-like%2F</url>
    <content type="text"><![CDATA[DOTA 数据集：http://captain.whu.edu.cn/DOTAweb/index.html COCO 数据集：http://cocodataset.org/#download COCO API：https://github.com/cocodataset/cocoapi API make 报错，安装 Cython 即可 1conda install cython COCO 数据集简介 COCO 数据集包含 instance，keypoint 和 caption 等部分，本文只介绍 instance 相关内容 COCO 数据集的组织方式 coco ├── annos.txt (optional) ├── annotations ├── classes.txt (optional) └── images annotations 文件夹放数据集的标注文件（json格式），images 文件夹放数据集的所有图片，（annos.txt 放数据集的原始标注文件，class.txt 放标注的类别名称，每行一个类别，不含背景） COCO 的数据标注格式 COCO 数据集以 json 文件格式存储数据集的标注信息，标注的格式可以参考 官网 和这个 知乎专栏，在这里就不重复了。 确定了标注的格式以后，分析 DOTA 数据集的标注格式，可以提取其中的信息然后以 json 格式存储下来就可以了 格式转换脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import jsonimport dota_utils as utilimport osfrom PIL import Imageinfo = &#123;"description": "DOTA dataset from WHU", "url": "http://caption.whu.edu.cn", "year": 2018, "version": "1.0"&#125;licenses = &#123;"url": "http://creativecommons.org/licenses/by-nc/2.0/", "id": 1, "name": "Attribution-NonCommercial License"&#125;categories = []for i, catName in enumerate(util.wordname_15, start=1): categories.append(&#123;"id": i, "name": "%s" % catName, "supercategory": "%s" % catName&#125;)images = []annotations = []aug = "/home/lxy/dota/data/aug"augmented = "/home/lxy/dota/data/augmented"train_small = "/home/lxy/dota/data/train_small"trainsplit_HBB = "/home/lxy/dota/data/trainsplit_HBB"val_small = "/home/lxy/dota/data/val_small"valsplit_HBB = "/home/lxy/dota/data/valsplit_HBB"dataset_path = [augmented, train_small, trainsplit_HBB, val_small, valsplit_HBB]imgid = 0annid = 0for path in dataset_path: img_path = os.path.join(path, "images") label_path = os.path.join(path, "labelTxt") for file in os.listdir(label_path): img_name = file.replace("txt", "png") im = Image.open(os.path.join(img_path, img_name)) w, h = im.size imgid += 1 images.append(&#123;"license": 1, "file_name": "%s" % img_name, \ "height": h, "width": w, "id": imgid&#125;) f = open(os.path.join(label_path, file)) for line in f.readlines(): line = "".join(line).strip("\n").split(" ") # a bbox has 4 points, a category name and a difficulty if len(line) != 10: print(path, file) else: annid += 1 catid = util.wordname_15.index(line[-2]) + 1 w_bbox = int(line[4][:-2]) - int(line[0][:-2]) h_bbox = int(line[5][:-2]) - int(line[1][:-2]) bbox = [line[0], line[1], str(w_bbox)+'.0', str(h_bbox)+'.0'] annotations.append(&#123;"id": annid, "image_id": imgid, "category_id": catid, \ "segmentation": [line[0:8]], "area": float(w_bbox*h_bbox), \ "bbox": bbox, "iscrowd": 0&#125;) f.close()my_json = &#123;"info": info, "licenses": licenses, "images": images, "annotations": annotations, "categories": categories&#125;with open("/home/lxy/dota/data/coco/annotations/train.json", "w+") as f: json.dump(my_json, f) print("writing json file done!") 检查转换结果 这里需要用到 COCO API，具体用法参考 repo 里的 demo 文件，读取转换完成的数据集并显示标注结果，观察标注是否有误 完]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>数据集</tag>
        <tag>COCO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NP-Hard问题]]></title>
    <url>%2F2018%2F12%2F07%2FNP-Hard%2F</url>
    <content type="text"><![CDATA[简单理解 NP, P, NP-Complete 和 NP-Hard 参考：https://www.cnblogs.com/sancyun/p/4250360.html P 是一类可以通过确定性图灵机（以下简称 图灵机）在多项式时间 (Polynomial time) 内解决的问题集合。 NP 是一类可以通过非确定性图灵机 ( Non-deterministic Turing Machine) 在多项式时间 (Polynomial time) 内解决的决策问题集合。 P 是 NP 的子集，也就是说任何可以被图灵机在多项式时间内解决的问题都可以被非确定性的图灵机解决。 接下来说说 NP 里最难得问题 NP-Complete。 其定义如下， 如果一个决策问题 L 是 NP-Complete 的，那么 L 具备以下两个性质： L 是 NP（给定一个解决 NP-Complete 的方案 (solution，感兴趣的读者可以思考一下 solution 和 answer 的区别)，可以很快验证是否可行，但不存在已知高效的方案 。） NP 里的任何问题可以在多项式时间内转为 L。 而 NP-Hard 只需要具备 NP-Complete 的第二个性质，因此 NP-Complete 是 NP-Hard 的子集。 这四者的关系如下图（假设 P!= NP）：]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>NP-Hard</tag>
      </tags>
  </entry>
</search>
